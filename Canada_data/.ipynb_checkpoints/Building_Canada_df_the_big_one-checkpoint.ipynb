{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dfccb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb68318",
   "metadata": {},
   "source": [
    "# Building a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea6b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a function to get thge station data from a csv, and turns it into a dataframe. \n",
    "def process_data(file):\n",
    "    \n",
    "    df1 = pd.read_csv(file, skiprows=30)\n",
    "    df1.drop(columns = ['S_G', 'BS', 'DwBS', 'BS%'], inplace = True)\n",
    "    df1['Year'] = int(file.split('_')[-2])\n",
    "    df1['Month'] = int(file.split('_')[-1].split('.')[0])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f863b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DataWorld/Canada1917-2017/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Grabs the data from each station in staion list, from each csv. \n",
    "canada_df_list = []\n",
    "path = '../DataWorld/Canada1917-2017/'\n",
    "for file in os.listdir(path):\n",
    "    try:\n",
    "        canada_df_list.append(process_data(path + file))\n",
    "    except:\n",
    "        print(path + file)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e01061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatieates all the dataframes in the canada_df_list inro one df\n",
    "canada_df_raw = pd.concat(canada_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720d473",
   "metadata": {},
   "source": [
    "# Clean New Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eece94d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stn_Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Tm</th>\n",
       "      <th>DwTm</th>\n",
       "      <th>D</th>\n",
       "      <th>Tx</th>\n",
       "      <th>DwTx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>...</th>\n",
       "      <th>S%N</th>\n",
       "      <th>P</th>\n",
       "      <th>DwP</th>\n",
       "      <th>P%N</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Clim_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABITIBI POST</td>\n",
       "      <td>48.717</td>\n",
       "      <td>-79.367</td>\n",
       "      <td>QC</td>\n",
       "      <td>-19.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1164.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7090050</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGASSIZ CDA</td>\n",
       "      <td>49.243</td>\n",
       "      <td>-121.760</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>...</td>\n",
       "      <td>406</td>\n",
       "      <td>256.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>20.0</td>\n",
       "      <td>549.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100120</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALBERNI BEAVER CREEK</td>\n",
       "      <td>49.367</td>\n",
       "      <td>-124.933</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>542.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1030180</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALERT BAY</td>\n",
       "      <td>50.583</td>\n",
       "      <td>-126.933</td>\n",
       "      <td>BC</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>460.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020270</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALIX</td>\n",
       "      <td>52.383</td>\n",
       "      <td>-113.167</td>\n",
       "      <td>AB</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1036.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3020120</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499637</th>\n",
       "      <td>YELLOW GRASS</td>\n",
       "      <td>49.817</td>\n",
       "      <td>-104.183</td>\n",
       "      <td>SK</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>310</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291</td>\n",
       "      <td>9.0</td>\n",
       "      <td>785.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4019040</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499638</th>\n",
       "      <td>YELLOWKNIFE A</td>\n",
       "      <td>62.463</td>\n",
       "      <td>-114.440</td>\n",
       "      <td>NT</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-27.5</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109</td>\n",
       "      <td>6.0</td>\n",
       "      <td>870.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2204100</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499639</th>\n",
       "      <td>YELLOWKNIFE CS</td>\n",
       "      <td>62.467</td>\n",
       "      <td>-114.450</td>\n",
       "      <td>NT</td>\n",
       "      <td>-10.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>862.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2204155</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499640</th>\n",
       "      <td>YOHO NP EMERALD LAKE</td>\n",
       "      <td>51.434</td>\n",
       "      <td>-116.540</td>\n",
       "      <td>BC</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>696.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117R00G</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499641</th>\n",
       "      <td>YORKTON A</td>\n",
       "      <td>51.267</td>\n",
       "      <td>-102.467</td>\n",
       "      <td>SK</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.1</td>\n",
       "      <td>...</td>\n",
       "      <td>307</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281</td>\n",
       "      <td>9.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4019080</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1499642 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Stn_Name     Lat     Long Prov    Tm  DwTm    D   Tx  \\\n",
       "0                ABITIBI POST  48.717  -79.367   QC -19.6   0.0  NaN  1.7   \n",
       "1                 AGASSIZ CDA  49.243 -121.760   BC   0.3   0.0 -3.1  8.9   \n",
       "2        ALBERNI BEAVER CREEK  49.367 -124.933   BC   0.5   0.0  NaN  9.4   \n",
       "3                   ALERT BAY  50.583 -126.933   BC   3.2   0.0  NaN  8.9   \n",
       "4                        ALIX  52.383 -113.167   AB -15.4   0.0  NaN  6.7   \n",
       "...                       ...     ...      ...  ...   ...   ...  ...  ...   \n",
       "1499637          YELLOW GRASS  49.817 -104.183   SK  -8.2   0.0 -3.8  5.0   \n",
       "1499638         YELLOWKNIFE A  62.463 -114.440   NT -11.0   0.0  2.7  1.3   \n",
       "1499639        YELLOWKNIFE CS  62.467 -114.450   NT -10.8   0.0  NaN  2.1   \n",
       "1499640  YOHO NP EMERALD LAKE  51.434 -116.540   BC  -6.0   1.0  NaN  5.0   \n",
       "1499641             YORKTON A  51.267 -102.467   SK  -8.9   0.0 -2.6  4.3   \n",
       "\n",
       "         DwTx    Tn  ...  S%N      P  DwP  P%N    Pd     HDD  CDD  Clim_ID  \\\n",
       "0         0.0 -38.3  ...  NaN   22.9  0.0  NaN   5.0  1164.5  0.0  7090050   \n",
       "1         0.0 -18.3  ...  406  256.5  0.0  107  20.0   549.4  0.0  1100120   \n",
       "2         0.0 -16.7  ...  NaN  136.1  0.0  NaN  13.0   542.1  0.0  1030180   \n",
       "3         0.0 -11.1  ...  NaN    186  0.0  NaN  21.0   460.1  0.0  1020270   \n",
       "4         0.0 -47.2  ...  NaN     42  0.0  NaN   9.0  1036.2  0.0  3020120   \n",
       "...       ...   ...  ...  ...    ...  ...  ...   ...     ...  ...      ...   \n",
       "1499637   0.0 -26.0  ...  310   48.4  0.0  291   9.0   785.5  0.0  4019040   \n",
       "1499638   0.0 -27.5  ...  123     27  0.0  109   6.0   870.5  0.0  2204100   \n",
       "1499639   0.0 -26.7  ...  NaN    NaN  NaN  NaN   NaN   862.9  0.0  2204155   \n",
       "1499640   0.0 -18.0  ...  NaN   43.5  0.0  NaN   4.0   696.8  0.0  117R00G   \n",
       "1499641   0.0 -24.1  ...  307   46.2  0.0  281   9.0   808.0  0.0  4019080   \n",
       "\n",
       "         Year  Month  \n",
       "0        1917      1  \n",
       "1        1917      1  \n",
       "2        1917      1  \n",
       "3        1917      1  \n",
       "4        1917      1  \n",
       "...       ...    ...  \n",
       "1499637  2000     11  \n",
       "1499638  2000     11  \n",
       "1499639  2000     11  \n",
       "1499640  2000     11  \n",
       "1499641  2000     11  \n",
       "\n",
       "[1499642 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorders the index to be more intuitve off of month and year.\n",
    "canada_df = canada_df_raw.sort_values(['Year','Month','Stn_Name'],ignore_index=True)\n",
    "canada_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc42a63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Tm</th>\n",
       "      <th>DwTm</th>\n",
       "      <th>D</th>\n",
       "      <th>Tx</th>\n",
       "      <th>DwTx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>DwTn</th>\n",
       "      <th>S</th>\n",
       "      <th>DwS</th>\n",
       "      <th>DwP</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.499222e+06</td>\n",
       "      <td>1.499222e+06</td>\n",
       "      <td>1.210243e+06</td>\n",
       "      <td>1.210243e+06</td>\n",
       "      <td>443830.000000</td>\n",
       "      <td>1.213688e+06</td>\n",
       "      <td>1.213688e+06</td>\n",
       "      <td>1.213145e+06</td>\n",
       "      <td>1.213145e+06</td>\n",
       "      <td>1.453448e+06</td>\n",
       "      <td>1.453448e+06</td>\n",
       "      <td>1.467205e+06</td>\n",
       "      <td>1.467205e+06</td>\n",
       "      <td>1.210243e+06</td>\n",
       "      <td>1.210243e+06</td>\n",
       "      <td>1.499642e+06</td>\n",
       "      <td>1.499642e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.979224e+01</td>\n",
       "      <td>-9.582673e+01</td>\n",
       "      <td>3.823694e+00</td>\n",
       "      <td>7.706791e-01</td>\n",
       "      <td>-0.398380</td>\n",
       "      <td>1.860966e+01</td>\n",
       "      <td>6.288667e-01</td>\n",
       "      <td>-1.102067e+01</td>\n",
       "      <td>6.177868e-01</td>\n",
       "      <td>1.451014e+01</td>\n",
       "      <td>2.831543e-01</td>\n",
       "      <td>3.844773e-01</td>\n",
       "      <td>8.767114e+00</td>\n",
       "      <td>4.266105e+02</td>\n",
       "      <td>8.229249e+00</td>\n",
       "      <td>1.968607e+03</td>\n",
       "      <td>6.533571e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.883639e+00</td>\n",
       "      <td>2.277140e+01</td>\n",
       "      <td>1.138994e+01</td>\n",
       "      <td>3.066763e+00</td>\n",
       "      <td>2.419865</td>\n",
       "      <td>1.088369e+01</td>\n",
       "      <td>2.765416e+00</td>\n",
       "      <td>1.434359e+01</td>\n",
       "      <td>2.737172e+00</td>\n",
       "      <td>2.571517e+01</td>\n",
       "      <td>2.208677e+00</td>\n",
       "      <td>2.505842e+00</td>\n",
       "      <td>4.715014e+00</td>\n",
       "      <td>3.293826e+02</td>\n",
       "      <td>2.064178e+01</td>\n",
       "      <td>2.094127e+01</td>\n",
       "      <td>3.412362e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.410000e+02</td>\n",
       "      <td>-5.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-23.300000</td>\n",
       "      <td>-4.990000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.300000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.917000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.635000e+01</td>\n",
       "      <td>-1.164170e+02</td>\n",
       "      <td>-4.400000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>9.900000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.220000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.401000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.955000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.935000e+01</td>\n",
       "      <td>-1.000330e+02</td>\n",
       "      <td>5.600000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.700000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>3.654000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.972000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.151700e+01</td>\n",
       "      <td>-7.514100e+01</td>\n",
       "      <td>1.330000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.010000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>6.621000e+02</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>1.985000e+03</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.251800e+01</td>\n",
       "      <td>8.100000e+00</td>\n",
       "      <td>2.690000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.940000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>7.259000e+02</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.089000e+03</td>\n",
       "      <td>2.726000e+02</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Lat          Long            Tm          DwTm              D  \\\n",
       "count  1.499222e+06  1.499222e+06  1.210243e+06  1.210243e+06  443830.000000   \n",
       "mean   4.979224e+01 -9.582673e+01  3.823694e+00  7.706791e-01      -0.398380   \n",
       "std    4.883639e+00  2.277140e+01  1.138994e+01  3.066763e+00       2.419865   \n",
       "min    0.000000e+00 -1.410000e+02 -5.000000e+01  0.000000e+00     -23.300000   \n",
       "25%    4.635000e+01 -1.164170e+02 -4.400000e+00  0.000000e+00      -1.600000   \n",
       "50%    4.935000e+01 -1.000330e+02  5.600000e+00  0.000000e+00      -0.300000   \n",
       "75%    5.151700e+01 -7.514100e+01  1.330000e+01  0.000000e+00       1.000000   \n",
       "max    8.251800e+01  8.100000e+00  2.690000e+01  3.000000e+01      16.700000   \n",
       "\n",
       "                 Tx          DwTx            Tn          DwTn             S  \\\n",
       "count  1.213688e+06  1.213688e+06  1.213145e+06  1.213145e+06  1.453448e+06   \n",
       "mean   1.860966e+01  6.288667e-01 -1.102067e+01  6.177868e-01  1.451014e+01   \n",
       "std    1.088369e+01  2.765416e+00  1.434359e+01  2.737172e+00  2.571517e+01   \n",
       "min   -4.990000e+01  0.000000e+00 -6.300000e+01  0.000000e+00  0.000000e+00   \n",
       "25%    9.900000e+00  0.000000e+00 -2.220000e+01  0.000000e+00  0.000000e+00   \n",
       "50%    2.000000e+01  0.000000e+00 -6.700000e+00  0.000000e+00  8.000000e-01   \n",
       "75%    2.800000e+01  0.000000e+00  5.000000e-01  0.000000e+00  2.010000e+01   \n",
       "max    4.500000e+01  3.000000e+01  2.940000e+01  3.000000e+01  7.259000e+02   \n",
       "\n",
       "                DwS           DwP            Pd           HDD           CDD  \\\n",
       "count  1.453448e+06  1.467205e+06  1.467205e+06  1.210243e+06  1.210243e+06   \n",
       "mean   2.831543e-01  3.844773e-01  8.767114e+00  4.266105e+02  8.229249e+00   \n",
       "std    2.208677e+00  2.505842e+00  4.715014e+00  3.293826e+02  2.064178e+01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  5.000000e+00  1.401000e+02  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  8.000000e+00  3.654000e+02  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  1.200000e+01  6.621000e+02  3.500000e+00   \n",
       "max    3.000000e+01  3.000000e+01  3.100000e+01  2.089000e+03  2.726000e+02   \n",
       "\n",
       "               Year         Month  \n",
       "count  1.499642e+06  1.499642e+06  \n",
       "mean   1.968607e+03  6.533571e+00  \n",
       "std    2.094127e+01  3.412362e+00  \n",
       "min    1.917000e+03  1.000000e+00  \n",
       "25%    1.955000e+03  4.000000e+00  \n",
       "50%    1.972000e+03  7.000000e+00  \n",
       "75%    1.985000e+03  9.000000e+00  \n",
       "max    2.000000e+03  1.200000e+01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows a table that gives basic statistical data, for each colunn that has numerical data.\n",
    "canada_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceaea599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stn_Name          0\n",
       "Lat             420\n",
       "Long            420\n",
       "Prov              0\n",
       "Tm           289399\n",
       "DwTm         289399\n",
       "D           1055812\n",
       "Tx           285954\n",
       "DwTx         285954\n",
       "Tn           286497\n",
       "DwTn         286497\n",
       "S             46194\n",
       "DwS           46194\n",
       "S%N         1145947\n",
       "P             32437\n",
       "DwP           32437\n",
       "P%N         1011463\n",
       "Pd            32437\n",
       "HDD          289399\n",
       "CDD          289399\n",
       "Clim_ID           0\n",
       "Year              0\n",
       "Month             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts all null values in each column \n",
    "canada_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36548900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stn_Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Tm</th>\n",
       "      <th>DwTm</th>\n",
       "      <th>D</th>\n",
       "      <th>Tx</th>\n",
       "      <th>DwTx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>...</th>\n",
       "      <th>S%N</th>\n",
       "      <th>P</th>\n",
       "      <th>DwP</th>\n",
       "      <th>P%N</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Clim_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALKALI LAKE</td>\n",
       "      <td>51.783</td>\n",
       "      <td>-122.283</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1090335</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANTICOSTI HEATH POINT</td>\n",
       "      <td>49.100</td>\n",
       "      <td>-61.700</td>\n",
       "      <td>QC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7050198</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ANTICOSTI WEST POINT</td>\n",
       "      <td>49.867</td>\n",
       "      <td>-64.533</td>\n",
       "      <td>QC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7050210</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BASHAW</td>\n",
       "      <td>52.683</td>\n",
       "      <td>-112.867</td>\n",
       "      <td>AB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3010535</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BEAR CREEK</td>\n",
       "      <td>48.500</td>\n",
       "      <td>-124.000</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010720</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499587</th>\n",
       "      <td>WHITE ROCK OCEAN PARK</td>\n",
       "      <td>49.042</td>\n",
       "      <td>-122.876</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1108913</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499601</th>\n",
       "      <td>WILLMAR</td>\n",
       "      <td>49.417</td>\n",
       "      <td>-102.500</td>\n",
       "      <td>SK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4018960</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499612</th>\n",
       "      <td>WINNIPEG SOUTH</td>\n",
       "      <td>49.783</td>\n",
       "      <td>-97.133</td>\n",
       "      <td>MB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502M001</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499622</th>\n",
       "      <td>WOODROW</td>\n",
       "      <td>49.567</td>\n",
       "      <td>-106.783</td>\n",
       "      <td>SK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>196</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4029030</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499631</th>\n",
       "      <td>WROXETER</td>\n",
       "      <td>43.863</td>\n",
       "      <td>-81.152</td>\n",
       "      <td>ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6129660</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289335 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Stn_Name     Lat     Long Prov  Tm  DwTm   D  Tx  DwTx  \\\n",
       "5                  ALKALI LAKE  51.783 -122.283   BC NaN   NaN NaN NaN   NaN   \n",
       "13       ANTICOSTI HEATH POINT  49.100  -61.700   QC NaN   NaN NaN NaN   NaN   \n",
       "15        ANTICOSTI WEST POINT  49.867  -64.533   QC NaN   NaN NaN NaN   NaN   \n",
       "34                      BASHAW  52.683 -112.867   AB NaN   NaN NaN NaN   NaN   \n",
       "38                  BEAR CREEK  48.500 -124.000   BC NaN   NaN NaN NaN   NaN   \n",
       "...                        ...     ...      ...  ...  ..   ...  ..  ..   ...   \n",
       "1499587  WHITE ROCK OCEAN PARK  49.042 -122.876   BC NaN   NaN NaN NaN   NaN   \n",
       "1499601                WILLMAR  49.417 -102.500   SK NaN   NaN NaN NaN   NaN   \n",
       "1499612         WINNIPEG SOUTH  49.783  -97.133   MB NaN   NaN NaN NaN   NaN   \n",
       "1499622                WOODROW  49.567 -106.783   SK NaN   NaN NaN NaN   NaN   \n",
       "1499631               WROXETER  43.863  -81.152   ON NaN   NaN NaN NaN   NaN   \n",
       "\n",
       "         Tn  ...  S%N      P  DwP  P%N    Pd  HDD CDD  Clim_ID  Year  Month  \n",
       "5       NaN  ...  NaN   25.2  0.0  NaN   9.0  NaN NaN  1090335  1917      1  \n",
       "13      NaN  ...  NaN    131  0.0  NaN  10.0  NaN NaN  7050198  1917      1  \n",
       "15      NaN  ...  NaN  135.8  0.0  NaN  17.0  NaN NaN  7050210  1917      1  \n",
       "34      NaN  ...  NaN   35.6  0.0  NaN   5.0  NaN NaN  3010535  1917      1  \n",
       "38      NaN  ...  NaN  415.3  0.0  NaN  23.0  NaN NaN  1010720  1917      1  \n",
       "...      ..  ...  ...    ...  ...  ...   ...  ...  ..      ...   ...    ...  \n",
       "1499587 NaN  ...    0     67  0.0   38  12.0  NaN NaN  1108913  2000     11  \n",
       "1499601 NaN  ...  232     69  0.0  366   9.0  NaN NaN  4018960  2000     11  \n",
       "1499612 NaN  ...  NaN   96.3  0.0  NaN  10.0  NaN NaN  502M001  2000     11  \n",
       "1499622 NaN  ...  196     24  0.0  159   5.0  NaN NaN  4029030  2000     11  \n",
       "1499631 NaN  ...  NaN  159.4  0.0  NaN  13.0  NaN NaN  6129660  2000     11  \n",
       "\n",
       "[289335 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This shows all the rows with a missing 'Tm' valure and, a missisng 'Tn' or 'Tx' value.\n",
    "# This does not give enough temp data for us to fill in the 'Tm' value for that row.\n",
    "canada_df[(canada_df['Tm'] != canada_df['Tm']) & \n",
    "          ((canada_df['Tx'] != canada_df['Tx']) | (canada_df['Tn'] != canada_df['Tn']))\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f507ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This drops all rows that have a missing 'Tm' value\n",
    "canada_df = canada_df.drop(canada_df[(canada_df['Tm'] != canada_df['Tm']) & \n",
    "                                     ((canada_df['Tx'] != canada_df['Tx']) |\n",
    "                                      (canada_df['Tn'] != canada_df['Tn']))].index\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0879dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'S' values into a list\n",
    "missing_S_idx = list(canada_df[canada_df['S'] != canada_df['S']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1374b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'S' by station and month\n",
    "snow_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b23d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'S' with the avgearge snowfall based on month and station\n",
    "\n",
    "for idx in missing_S_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_S = snow_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_S == avg_S:\n",
    "                canada_df.at[idx,'S'] = avg_S\n",
    "          \n",
    "        # some staions have null values for a month , so using the average snowfallin the entire dataframe for that month \n",
    "            elif avg_S != avg_S:\n",
    "                canada_df.at[idx,'S'] = canada_df.groupby('Month')['S'].mean()[month]\n",
    "                \n",
    "# some stations have no data for 'S', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'S'] =canada_df.groupby('Month')['S'].mean()[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5adc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'S' by station and month\n",
    "DwS_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'DwS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "284e5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'DwS' values into a list\n",
    "missing_DwS_idx = list(canada_df[canada_df['DwS'] != canada_df['DwS']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ccc62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'DwS' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_DwS_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_DwS = DwS_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_DwS == avg_DwS:\n",
    "                canada_df.at[idx,'DwS'] = avg_DwS\n",
    "          \n",
    "        # some staions have null values for a month , so using the average 'DwS in the entire dataframe for that month \n",
    "            elif avg_DwS != avg_DwS:\n",
    "                canada_df.at[idx,'DwS'] = canada_df.groupby('Month')['DwS'].mean()[month]\n",
    "                \n",
    "# some stations have no data for 'DwS', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'DwS'] =canada_df.groupby('Month')['DwS'].mean()[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2823cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the 'D', 'S%N', and 'P%N' columns since the amount of  missing data\n",
    "canada_df.drop(columns = ['D', 'P%N', 'S&N'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c99c7e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stn_Name        0\n",
       "Lat             0\n",
       "Long            0\n",
       "Prov            0\n",
       "Tm             64\n",
       "DwTm           64\n",
       "Tx              5\n",
       "DwTx            5\n",
       "Tn              0\n",
       "DwTn            0\n",
       "S               0\n",
       "DwS             0\n",
       "P           26029\n",
       "DwP         26029\n",
       "Pd          26029\n",
       "HDD            64\n",
       "CDD            64\n",
       "Clim_ID         0\n",
       "Year            0\n",
       "Month           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canada_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14b45954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>DwP</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Clim_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8200150</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1411.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6020381</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160465</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1022.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3030856</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1164.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4011090</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499602</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305PE6R</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499629</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>368.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8404340</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>747.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40190LN</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499634</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>676.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3057673</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>862.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2204155</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26029 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           P  DwP  Pd     HDD  CDD  Clim_ID  Year  Month\n",
       "16       NaN  NaN NaN   810.0  0.0  8200150  1917      1\n",
       "22       NaN  NaN NaN  1411.3  0.0  6020381  1917      1\n",
       "26       NaN  NaN NaN   937.0  0.0  6160465  1917      1\n",
       "61       NaN  NaN NaN  1022.8  0.0  3030856  1917      1\n",
       "68       NaN  NaN NaN  1164.9  0.0  4011090  1917      1\n",
       "...      ...  ...  ..     ...  ...      ...   ...    ...\n",
       "1499602  NaN  NaN NaN   756.7  0.0  305PE6R  2000     11\n",
       "1499629  NaN  NaN NaN   368.8  0.0  8404340  2000     11\n",
       "1499633  NaN  NaN NaN   747.2  0.0  40190LN  2000     11\n",
       "1499634  NaN  NaN NaN   676.3  0.0  3057673  2000     11\n",
       "1499639  NaN  NaN NaN   862.9  0.0  2204155  2000     11\n",
       "\n",
       "[26029 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The values with missing precicpitation data are missing the data from the relevent rows also.\n",
    "canada_df[(canada_df['P']!=canada_df['P'])].loc[:,'P':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c1927a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treats '######' as a null value for the column 'P'\n",
    "canada_df['P'] = np.where(canada_df['P'] == '######',np.nan,canada_df['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the data type of 'P' to float\n",
    "canada_df['P'] = canada_df['P'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "946fb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'P' values into a list\n",
    "missing_P_idx = list(canada_df[canada_df['P'] != canada_df['P']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "004ed756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'P' by station and month\n",
    "P_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7fcbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'P' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_P_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_P = P_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_P == avg_P:\n",
    "                canada_df.at[idx,'P'] = avg_P\n",
    "          \n",
    "        # some staions have null values for a month , so using the average 'P in the entire dataframe for that month \n",
    "            elif avg_P != avg_P:\n",
    "                canada_df.at[idx,'P'] = canada_df.groupby('Month')['P'].mean()[month]\n",
    "                \n",
    "# some stations have no data for 'P', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'P'] =canada_df.groupby('Month')['P'].mean()[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca637576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'Pd' values into a list\n",
    "missing_Pd_idx = list(canada_df[canada_df['Pd'] != canada_df['Pd']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ada0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'Pd' by station and month\n",
    "Pd_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'Pd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a303964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'Pd' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_Pd_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_Pd = Pd_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_Pd == avg_Pd:\n",
    "                canada_df.at[idx,'Pd'] = avg_Pd\n",
    "          \n",
    "        # some staions have null values for a month , so using the average 'Pd in the entire dataframe for that month \n",
    "            elif avg_Pd != avg_Pd:\n",
    "                canada_df.at[idx,'Pd'] = canada_df.groupby('Month')['Pd'].mean()[month]\n",
    "                \n",
    "# some stations have no data for 'Pd', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'Pd'] =canada_df.groupby('Month')['Pd'].mean()[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71701b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'DwP' values into a list\n",
    "missing_DwP_idx = list(canada_df[canada_df['DwP'] != canada_df['DwP']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fcfc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'Pd' by station and month\n",
    "DwP_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'DwP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75d81d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'DwP' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_DwP_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_DwP = DwP_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_DwP == avg_DwP:\n",
    "                canada_df.at[idx,'DwP'] = avg_DwP\n",
    "          \n",
    "        # some staions have null values for a month , so using the average 'DwP in the entire dataframe for that month \n",
    "            elif avg_DwP != avg_DwP:\n",
    "                canada_df.at[idx,'DwP'] = canada_df.groupby('Month')['DwP'].mean()[month]\n",
    "                \n",
    "# some stations have no data for 'DwP', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'DwP'] =canada_df.groupby('Month')['DwP'].mean()[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60e863fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'Tm' value\n",
    "missing_Tm_idx = list(canada_df[canada_df['Tm'] != canada_df['Tm']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbc20c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages out the high and low for the month to get the value for the missing monthly average \n",
    "for idx in missing_Tm_idx:\n",
    "    \n",
    "        canada_df.at[idx,'Tm'] = (canada_df.at[idx,'Tn'] + canada_df.at[idx,'Tx']) / 2\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e856376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'DwTm' value\n",
    "missing_DwTm_idx = list(canada_df[canada_df['DwTm'] != canada_df['DwTm']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87903d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces the missing 'DwTm' values with 0 \n",
    "for idx in missing_DwTm_idx:\n",
    "    \n",
    "        canada_df.at[idx,'DwTm'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a158029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'DwTx' value\n",
    "missing_DwTx_idx = list(canada_df[canada_df['DwTx'] != canada_df['DwTx']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "305abe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces the missing 'DwTx' values with 0 \n",
    "for idx in missing_DwTx_idx:\n",
    "    \n",
    "        canada_df.at[idx,'DwTx'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00df946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'Tx' value\n",
    "missing_Tx_idx = list(canada_df[canada_df['Tx'] != canada_df['Tx']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef256fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'Pd' by station and month\n",
    "Tx_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'Tx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f13c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'Tx' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_Tx_idx:\n",
    "        station = canada_df.at[idx,'Stn_Name']\n",
    "        month = canada_df.at[idx,'Month']\n",
    "        avg_Tx = Tx_pt.loc[station,month]    \n",
    "            \n",
    "        canada_df.at[idx,'Tx'] = avg_Tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b94ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'HDD' and 'CDD' values\n",
    "missing_HDD_idx = list(canada_df[(canada_df['HDD'] != canada_df['HDD']) & canada_df['CDD'] != canada_df['CDD']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04536218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'HDD' by station and month\n",
    "HDD_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'HDD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9ed9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'CDD' by station and month\n",
    "CDD_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'CDD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6758f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'HDD' and \"CDD\" with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_HDD_idx:\n",
    "        station = canada_df.at[idx,'Stn_Name']\n",
    "        month = canada_df.at[idx,'Month']\n",
    "        avg_HDD = HDD_pt.loc[station,month]    \n",
    "        avg_CDD = CDD_pt.loc[station,month]\n",
    "        \n",
    "        canada_df.at[idx,'HDD'] = avg_HDD\n",
    "        \n",
    "        canada_df.at[idx,'CDD'] = avg_CDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d974dd97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "canada_df.to_csv('./canada_big_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc6349c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1210307, 20)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canada_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a63f81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('canada_big_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b686e6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1210307, 21)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee90d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Unnamed: 0',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8eeee621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[:100_000,]\n",
    "\n",
    "df2 = df.loc[100_001:200_000,]\n",
    "\n",
    "df3 = df.loc[200_001:300_000,]\n",
    "\n",
    "df4 = df.loc[300_001:400_000,]\n",
    "\n",
    "df5 = df.loc[400_001:500_000,]\n",
    "\n",
    "df6 = df.loc[500_001:600_000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eeee894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df.loc[600_001:700_000,]\n",
    "\n",
    "df8 = df.loc[700_001:800_000,]\n",
    "\n",
    "df9 = df.loc[800_001:900_000,]\n",
    "\n",
    "df10 = df.loc[900_001:1_000_000,]\n",
    "\n",
    "df11 = df.loc[1_000_001:1_100_000,]\n",
    "\n",
    "df12= df.loc[1_100_001:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e009b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('canada_big_df_pt1.csv', index=False)\n",
    "\n",
    "df2.to_csv('canada_big_df_pt2.csv', index=False)\n",
    "\n",
    "df3.to_csv('canada_big_df_pt3.csv', index=False)\n",
    "\n",
    "df4.to_csv('canada_big_df_pt4.csv', index=False)\n",
    "\n",
    "df5.to_csv('canada_big_df_pt5.csv', index=False)\n",
    "\n",
    "df6.to_csv('canada_big_df_pt6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32e4d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.to_csv('canada_big_df_pt7.csv', index=False)\n",
    "\n",
    "df8.to_csv('canada_big_df_pt8.csv', index=False)\n",
    "\n",
    "df9.to_csv('canada_big_df_pt9.csv', index=False)\n",
    "\n",
    "df10.to_csv('canada_big_df_pt10.csv', index=False)\n",
    "\n",
    "df11.to_csv('canada_big_df_pt11.csv', index=False)\n",
    "\n",
    "df12.to_csv('canada_big_df_pt12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df8ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
