{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c7f87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3984a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this csv contains all the data from canadian weather stations from 1917-2017\n",
    "df = pd.read_csv('./data/canada_all_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e6b01e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9817f74d6b7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'decade'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4162\u001b[0m         \"\"\"\n\u001b[1;32m-> 4163\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3887\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3921\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5281\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5282\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# the csv was saved with an index droping the index column\n",
    "df.drop(columns='Unnamed: 0', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a new column that called decade. The value reflects how many decades the after 1910 the data was recorded  \n",
    "\n",
    "dec ={'1910':0, '1920':1, '1930':2, '1940':3, '1950':4, '1960':5, '1970':6, '1980':7,\n",
    "       '1990':8, '2000':9, '2010':10}\n",
    "df['decade'] = df['Year']//10 *10\n",
    "df['decade'] = df['decade'].astype(str)\n",
    "df['decade']=   df['decade'].map(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c770d694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     0.148362\n",
       "6     0.145253\n",
       "8     0.131075\n",
       "5     0.123600\n",
       "9     0.099980\n",
       "4     0.098478\n",
       "3     0.079141\n",
       "2     0.063546\n",
       "1     0.049516\n",
       "10    0.049088\n",
       "0     0.011960\n",
       "Name: decade, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the baseline of each decade\n",
    "df['decade'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538808a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the dataframe contain only stations with more than 30 years worth of observations\n",
    "\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/29836836/how-do-i-filter-a-pandas-dataframe-based-on-value-counts\n",
    "\n",
    "\n",
    "df = df.groupby(\"Clim_ID\").filter(lambda x: len(x) > 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c5c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the features for the model to be all numerical values in our dataset, and sets out target to what decade the data came from\n",
    "\n",
    "X= df.drop(columns= ['Stn_Name', 'Prov', 'Clim_ID', 'decade', 'Year'])\n",
    "y = df['decade']\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3babdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scales the data\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817d1518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2388341578227841, 0.22741238372639294)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did a quick randomforest model with max depth of 10\n",
    "rf =RandomForestClassifier(max_depth=10)\n",
    "rf.fit(X_train_sc,y_train)\n",
    "rf.score(X_train_sc,y_train), rf.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b1dee50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999874721450976, 0.41590247110777034)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# made a random forest model with a max depth of 100\n",
    "# the score \n",
    "rf =RandomForestClassifier(max_depth=100)\n",
    "rf.fit(X_train_sc,y_train)\n",
    "rf.score(X_train_sc,y_train), rf.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b83c1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sets X and y and transform y into an arry to show which decade its in.\n",
    "\n",
    "X= df.drop(columns= ['Stn_Name', 'Prov', 'Clim_ID', 'decade', 'Year'])\n",
    "y = df['decade']\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "# splits X and y into train and test\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y, stratify=y)\n",
    "\n",
    "\n",
    "# scales X and y\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1fe4c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a neural nets  model\n",
    "nn= Sequential()\n",
    "\n",
    "#  2 hidden layers\n",
    "nn.add(Dense(32, input_dim=X_train_sc.shape[1], activation='relu'))\n",
    "nn.add(Dense(32, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(Dense(11, activation='softmax'))\n",
    "\n",
    "# compiles model\n",
    "nn.compile(loss ='categorical_crossentropy', optimizer= 'adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c191a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19956/19956 [==============================] - 10s 488us/step - loss: 2.1940 - acc: 0.1813 - val_loss: 2.1487 - val_acc: 0.1986\n",
      "Epoch 2/10\n",
      "19956/19956 [==============================] - 10s 485us/step - loss: 2.1446 - acc: 0.2018 - val_loss: 2.1402 - val_acc: 0.1995\n",
      "Epoch 3/10\n",
      "19956/19956 [==============================] - 10s 494us/step - loss: 2.1330 - acc: 0.2063 - val_loss: 2.1291 - val_acc: 0.2075\n",
      "Epoch 4/10\n",
      "19956/19956 [==============================] - 10s 496us/step - loss: 2.1261 - acc: 0.2098 - val_loss: 2.1246 - val_acc: 0.2091\n",
      "Epoch 5/10\n",
      "19956/19956 [==============================] - 10s 494us/step - loss: 2.1204 - acc: 0.2126 - val_loss: 2.1223 - val_acc: 0.2116\n",
      "Epoch 6/10\n",
      "19956/19956 [==============================] - 10s 493us/step - loss: 2.1166 - acc: 0.2139 - val_loss: 2.1218 - val_acc: 0.2096\n",
      "Epoch 7/10\n",
      "19956/19956 [==============================] - 10s 492us/step - loss: 2.1129 - acc: 0.2148 - val_loss: 2.1188 - val_acc: 0.2116\n",
      "Epoch 8/10\n",
      "19956/19956 [==============================] - 10s 490us/step - loss: 2.1111 - acc: 0.2153 - val_loss: 2.1120 - val_acc: 0.2146\n",
      "Epoch 9/10\n",
      "19956/19956 [==============================] - 10s 485us/step - loss: 2.1095 - acc: 0.2157 - val_loss: 2.1140 - val_acc: 0.2144\n",
      "Epoch 10/10\n",
      "19956/19956 [==============================] - 10s 484us/step - loss: 2.1100 - acc: 0.2161 - val_loss: 2.1081 - val_acc: 0.2166\n"
     ]
    }
   ],
   "source": [
    "# fits our model\n",
    "results = nn.fit(X_train_sc, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b9b5324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2495/2495 [==============================] - 16s 6ms/step - loss: 2.1677 - acc: 0.1934 - val_loss: 2.0992 - val_acc: 0.2239\n",
      "Epoch 2/16\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 2.0739 - acc: 0.2360 - val_loss: 2.0259 - val_acc: 0.2594\n",
      "Epoch 3/16\n",
      "2495/2495 [==============================] - 15s 6ms/step - loss: 2.0070 - acc: 0.2666 - val_loss: 1.9757 - val_acc: 0.2813\n",
      "Epoch 4/16\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.9488 - acc: 0.2922 - val_loss: 1.9406 - val_acc: 0.2964\n",
      "Epoch 5/16\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8975 - acc: 0.3139 - val_loss: 1.9050 - val_acc: 0.3123\n",
      "Epoch 6/16\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8583 - acc: 0.3277 - val_loss: 1.8764 - val_acc: 0.3245\n",
      "Epoch 7/16\n",
      "2495/2495 [==============================] - 15s 6ms/step - loss: 1.8244 - acc: 0.3425 - val_loss: 1.8574 - val_acc: 0.3316\n",
      "Epoch 8/16\n",
      "2495/2495 [==============================] - 15s 6ms/step - loss: 1.7937 - acc: 0.3554 - val_loss: 1.8471 - val_acc: 0.3364\n",
      "Epoch 9/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7687 - acc: 0.3637 - val_loss: 1.8361 - val_acc: 0.3420\n",
      "Epoch 10/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7497 - acc: 0.3717 - val_loss: 1.8278 - val_acc: 0.3447\n",
      "Epoch 11/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7280 - acc: 0.3791 - val_loss: 1.8194 - val_acc: 0.3491\n",
      "Epoch 12/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7097 - acc: 0.3883 - val_loss: 1.8077 - val_acc: 0.3548\n",
      "Epoch 13/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6923 - acc: 0.3928 - val_loss: 1.8089 - val_acc: 0.3548\n",
      "Epoch 14/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6766 - acc: 0.3993 - val_loss: 1.8027 - val_acc: 0.3587\n",
      "Epoch 15/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6632 - acc: 0.4046 - val_loss: 1.8014 - val_acc: 0.3596\n",
      "Epoch 16/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6499 - acc: 0.4088 - val_loss: 1.7958 - val_acc: 0.3625\n"
     ]
    }
   ],
   "source": [
    "# let's create our model\n",
    "nn= Sequential()\n",
    "# hidden layers\n",
    "nn.add(Dense(512, input_dim=X_train_sc.shape[1], activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(Dense(11, activation='softmax'))\n",
    "\n",
    "\n",
    "#compiles model\n",
    "nn.compile(loss ='categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
    "\n",
    "results = nn.fit(X_train_sc, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=16,\n",
    "                    validation_data=(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "95bc28b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2495/2495 [==============================] - 20s 8ms/step - loss: 2.1690 - acc: 0.1918 - val_loss: 2.0881 - val_acc: 0.2283\n",
      "Epoch 2/16\n",
      "2495/2495 [==============================] - 20s 8ms/step - loss: 2.0690 - acc: 0.2366 - val_loss: 2.0218 - val_acc: 0.2578\n",
      "Epoch 3/16\n",
      "2495/2495 [==============================] - 18s 7ms/step - loss: 1.9864 - acc: 0.2749 - val_loss: 1.9509 - val_acc: 0.2909\n",
      "Epoch 4/16\n",
      "2495/2495 [==============================] - 18s 7ms/step - loss: 1.9109 - acc: 0.3063 - val_loss: 1.9001 - val_acc: 0.3123\n",
      "Epoch 5/16\n",
      "2495/2495 [==============================] - 18s 7ms/step - loss: 1.8513 - acc: 0.3306 - val_loss: 1.8656 - val_acc: 0.3278\n",
      "Epoch 6/16\n",
      "2495/2495 [==============================] - 19s 8ms/step - loss: 1.8015 - acc: 0.3509 - val_loss: 1.8297 - val_acc: 0.3402\n",
      "Epoch 7/16\n",
      "2495/2495 [==============================] - 20s 8ms/step - loss: 1.7594 - acc: 0.3657 - val_loss: 1.8211 - val_acc: 0.3470\n",
      "Epoch 8/16\n",
      "2495/2495 [==============================] - 20s 8ms/step - loss: 1.7261 - acc: 0.3782 - val_loss: 1.8054 - val_acc: 0.3522\n",
      "Epoch 9/16\n",
      "2495/2495 [==============================] - 20s 8ms/step - loss: 1.6932 - acc: 0.3905 - val_loss: 1.7892 - val_acc: 0.3614\n",
      "Epoch 10/16\n",
      "2495/2495 [==============================] - 19s 8ms/step - loss: 1.6656 - acc: 0.4021 - val_loss: 1.7932 - val_acc: 0.3599\n",
      "Epoch 11/16\n",
      "2495/2495 [==============================] - 19s 8ms/step - loss: 1.6390 - acc: 0.4106 - val_loss: 1.7787 - val_acc: 0.3667\n",
      "Epoch 12/16\n",
      "2495/2495 [==============================] - 19s 8ms/step - loss: 1.6167 - acc: 0.4204 - val_loss: 1.7707 - val_acc: 0.3712\n",
      "Epoch 13/16\n",
      "2495/2495 [==============================] - 20s 8ms/step - loss: 1.5928 - acc: 0.4280 - val_loss: 1.7822 - val_acc: 0.3690\n",
      "Epoch 14/16\n",
      "2495/2495 [==============================] - 19s 8ms/step - loss: 1.5717 - acc: 0.4361 - val_loss: 1.7733 - val_acc: 0.3749\n",
      "Epoch 15/16\n",
      "2495/2495 [==============================] - 18s 7ms/step - loss: 1.5510 - acc: 0.4436 - val_loss: 1.7758 - val_acc: 0.3743\n",
      "Epoch 16/16\n",
      "2495/2495 [==============================] - 18s 7ms/step - loss: 1.5348 - acc: 0.4479 - val_loss: 1.7784 - val_acc: 0.3769\n"
     ]
    }
   ],
   "source": [
    "# let's create our model\n",
    "nn= Sequential()\n",
    "# hidden layers\n",
    "nn.add(Dense(512, input_dim=X_train_sc.shape[1], activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(Dense(11, activation='softmax'))\n",
    "\n",
    "# compiles model\n",
    "nn.compile(loss ='categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
    "\n",
    "results = nn.fit(X_train_sc, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=16,\n",
    "                    validation_data=(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "845c5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data with PCA\n",
    "pca=PCA()\n",
    "pca.fit(X_train_sc)\n",
    "Z_train =pca.transform(X_train_sc)\n",
    "Z_test = pca.transform(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "881c1786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance for each component): [0.29250123 0.24555788 0.13175641 0.08162141 0.05747355 0.05360277\n",
      " 0.04149689 0.03025271 0.02440467 0.01465115]\n"
     ]
    }
   ],
   "source": [
    "# transform the data with PCA\n",
    "\n",
    "pca=PCA(n_components=10)\n",
    "pca.fit(X_train_sc)\n",
    "Z_train =pca.transform(X_train_sc)\n",
    "Z_test = pca.transform(X_test_sc)\n",
    "var_exp =pca.explained_variance_ratio_\n",
    "print(f'Explained variance for each component): {var_exp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "44d8376c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 2.1823 - acc: 0.1870 - val_loss: 2.1321 - val_acc: 0.2078\n",
      "Epoch 2/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.1191 - acc: 0.2133 - val_loss: 2.0980 - val_acc: 0.2241\n",
      "Epoch 3/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.0824 - acc: 0.2306 - val_loss: 2.0716 - val_acc: 0.2362\n",
      "Epoch 4/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.0497 - acc: 0.2455 - val_loss: 2.0440 - val_acc: 0.2487\n",
      "Epoch 5/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.0237 - acc: 0.2578 - val_loss: 2.0259 - val_acc: 0.2571\n",
      "Epoch 6/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.0012 - acc: 0.2663 - val_loss: 2.0162 - val_acc: 0.2626\n",
      "Epoch 7/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.9810 - acc: 0.2748 - val_loss: 2.0026 - val_acc: 0.2670\n",
      "Epoch 8/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.9618 - acc: 0.2824 - val_loss: 1.9958 - val_acc: 0.2703\n",
      "Epoch 9/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.9450 - acc: 0.2890 - val_loss: 1.9889 - val_acc: 0.2740\n",
      "Epoch 10/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.9327 - acc: 0.2933 - val_loss: 1.9840 - val_acc: 0.2760\n",
      "Epoch 11/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.9173 - acc: 0.3007 - val_loss: 1.9747 - val_acc: 0.2808\n",
      "Epoch 12/25\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.9040 - acc: 0.3061 - val_loss: 1.9671 - val_acc: 0.2826\n",
      "Epoch 13/25\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.8933 - acc: 0.3106 - val_loss: 1.9665 - val_acc: 0.2844\n",
      "Epoch 14/25\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8812 - acc: 0.3155 - val_loss: 1.9620 - val_acc: 0.2875\n",
      "Epoch 15/25\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8713 - acc: 0.3187 - val_loss: 1.9585 - val_acc: 0.2885\n",
      "Epoch 16/25\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8609 - acc: 0.3222 - val_loss: 1.9603 - val_acc: 0.2884\n",
      "Epoch 17/25\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8490 - acc: 0.3261 - val_loss: 1.9514 - val_acc: 0.2923\n",
      "Epoch 18/25\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.8406 - acc: 0.3302 - val_loss: 1.9508 - val_acc: 0.2936\n",
      "Epoch 19/25\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8327 - acc: 0.3329 - val_loss: 1.9522 - val_acc: 0.2942\n",
      "Epoch 20/25\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.8247 - acc: 0.3362 - val_loss: 1.9526 - val_acc: 0.2962\n",
      "Epoch 21/25\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8128 - acc: 0.3412 - val_loss: 1.9452 - val_acc: 0.2970\n",
      "Epoch 22/25\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.8072 - acc: 0.3430 - val_loss: 1.9417 - val_acc: 0.2983\n",
      "Epoch 23/25\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.7980 - acc: 0.3474 - val_loss: 1.9498 - val_acc: 0.2992\n",
      "Epoch 24/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7896 - acc: 0.3505 - val_loss: 1.9481 - val_acc: 0.3000\n",
      "Epoch 25/25\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7826 - acc: 0.3527 - val_loss: 1.9414 - val_acc: 0.3003\n"
     ]
    }
   ],
   "source": [
    "# Makes a neural net model with the PCA transformed data\n",
    "nn= Sequential()\n",
    "# hidden layers\n",
    "nn.add(Dense(512, input_dim=Z_train.shape[1], activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "\n",
    "\n",
    "# output layer\n",
    "nn.add(Dense(11, activation='softmax'))\n",
    "\n",
    "# compiles model\n",
    "nn.compile(loss ='categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
    "\n",
    "results1 = nn.fit(Z_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=25,\n",
    "                    validation_data=(Z_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f8745b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just using features that record temp\n",
    "X= df[['Tx','Tn','Tm']]\n",
    "y = df['decade']\n",
    "\n",
    "y = to_categorical(y)\n",
    "X_train_t, X_test_t,y_train_t,y_test_t = train_test_split(X,y, stratify=y)\n",
    "\n",
    "sc_t = StandardScaler()\n",
    "\n",
    "X_train_t_sc = sc_t.fit_transform(X_train_t)\n",
    "X_test_t_sc = sc_t.transform(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91659b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2667 - acc: 0.1505 - val_loss: 2.2582 - val_acc: 0.1565\n",
      "Epoch 2/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2564 - acc: 0.1567 - val_loss: 2.2532 - val_acc: 0.1616\n",
      "Epoch 3/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2525 - acc: 0.1604 - val_loss: 2.2501 - val_acc: 0.1631\n",
      "Epoch 4/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2498 - acc: 0.1624 - val_loss: 2.2490 - val_acc: 0.1647\n",
      "Epoch 5/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2480 - acc: 0.1643 - val_loss: 2.2478 - val_acc: 0.1655\n",
      "Epoch 6/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2461 - acc: 0.1656 - val_loss: 2.2459 - val_acc: 0.1663\n",
      "Epoch 7/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2439 - acc: 0.1665 - val_loss: 2.2451 - val_acc: 0.1663\n",
      "Epoch 8/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2435 - acc: 0.1678 - val_loss: 2.2443 - val_acc: 0.1677\n",
      "Epoch 9/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2432 - acc: 0.1694 - val_loss: 2.2429 - val_acc: 0.1678\n",
      "Epoch 10/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2434 - acc: 0.1695 - val_loss: 2.2435 - val_acc: 0.1678\n",
      "Epoch 11/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2418 - acc: 0.1690 - val_loss: 2.2424 - val_acc: 0.1699\n",
      "Epoch 12/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2399 - acc: 0.1702 - val_loss: 2.2419 - val_acc: 0.1697\n",
      "Epoch 13/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2397 - acc: 0.1712 - val_loss: 2.2419 - val_acc: 0.1680\n",
      "Epoch 14/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2402 - acc: 0.1700 - val_loss: 2.2418 - val_acc: 0.1696\n",
      "Epoch 15/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2395 - acc: 0.1702 - val_loss: 2.2414 - val_acc: 0.1689\n",
      "Epoch 16/16\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.2382 - acc: 0.1717 - val_loss: 2.2420 - val_acc: 0.1687\n"
     ]
    }
   ],
   "source": [
    "# creates a model that uses features that record temp\n",
    "nn_t= Sequential()\n",
    "# 1st hidden layer\n",
    "nn_t.add(Dense(512, input_dim=X_train_t_sc.shape[1], activation='relu'))\n",
    "nn_t.add(Dense(512, activation='relu'))\n",
    "nn_t.add(Dense(512, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn_t.add(Dense(11, activation='softmax'))\n",
    "\n",
    "nn_t.compile(loss ='categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
    "\n",
    "results_t = nn_t.fit(X_train_t_sc, y_train_t,\n",
    "                    batch_size=256,\n",
    "                    epochs=16,\n",
    "                    validation_data=(X_test_t_sc,y_test_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "31ab208e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2495/2495 [==============================] - 44s 18ms/step - loss: 2.2083 - acc: 0.1770 - val_loss: 2.1458 - val_acc: 0.2004\n",
      "Epoch 2/16\n",
      "2495/2495 [==============================] - 44s 18ms/step - loss: 2.1574 - acc: 0.1974 - val_loss: 2.1285 - val_acc: 0.2085\n",
      "Epoch 3/16\n",
      "2495/2495 [==============================] - 44s 18ms/step - loss: 2.1448 - acc: 0.2017 - val_loss: 2.1133 - val_acc: 0.2182\n",
      "Epoch 4/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.1347 - acc: 0.2061 - val_loss: 2.1070 - val_acc: 0.2205\n",
      "Epoch 5/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.1264 - acc: 0.2106 - val_loss: 2.0936 - val_acc: 0.2265\n",
      "Epoch 6/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.1222 - acc: 0.2115 - val_loss: 2.0906 - val_acc: 0.2288\n",
      "Epoch 7/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.1163 - acc: 0.2149 - val_loss: 2.0802 - val_acc: 0.2327\n",
      "Epoch 8/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.1099 - acc: 0.2178 - val_loss: 2.0757 - val_acc: 0.2345\n",
      "Epoch 9/16\n",
      "2495/2495 [==============================] - 44s 18ms/step - loss: 2.1048 - acc: 0.2197 - val_loss: 2.0675 - val_acc: 0.2394\n",
      "Epoch 10/16\n",
      "2495/2495 [==============================] - 44s 18ms/step - loss: 2.1015 - acc: 0.2223 - val_loss: 2.0652 - val_acc: 0.2398\n",
      "Epoch 11/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.0991 - acc: 0.2225 - val_loss: 2.0691 - val_acc: 0.2404\n",
      "Epoch 12/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.0938 - acc: 0.2241 - val_loss: 2.0600 - val_acc: 0.2441\n",
      "Epoch 13/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.0921 - acc: 0.2259 - val_loss: 2.0539 - val_acc: 0.2497\n",
      "Epoch 14/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.0877 - acc: 0.2281 - val_loss: 2.0492 - val_acc: 0.2501\n",
      "Epoch 15/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.0855 - acc: 0.2296 - val_loss: 2.0464 - val_acc: 0.2504\n",
      "Epoch 16/16\n",
      "2495/2495 [==============================] - 43s 17ms/step - loss: 2.0838 - acc: 0.2306 - val_loss: 2.0450 - val_acc: 0.2548\n"
     ]
    }
   ],
   "source": [
    "# create a model using dropout\n",
    "nn_dropout= Sequential()\n",
    "# hidden layer\n",
    "nn_dropout.add(Dense(1024, input_dim=X_train_sc.shape[1], activation='relu'))\n",
    "\n",
    "nn_dropout.add(Dropout(.5))\n",
    "\n",
    "nn_dropout.add(Dense(1024, activation='relu'))\n",
    "\n",
    "nn_dropout.add(Dropout(.5))\n",
    "\n",
    "nn_dropout.add(Dense(1024, activation='relu'))\n",
    "\n",
    "nn_dropout.add(Dropout(.5))\n",
    "# output layer\n",
    "nn_dropout.add(Dense(11, activation='softmax'))\n",
    "\n",
    "nn_dropout.compile(loss ='categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
    "\n",
    "results1 = nn_dropout.fit(X_train_sc, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=16,\n",
    "                    validation_data=(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be5b09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds a new column that multiplies longitude and lattitude together\n",
    "df['LxL'] = df['Long'] * df['Lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7e0c1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds the column 'LxL' to the feature used to model with\n",
    "X= df.drop(columns= ['Stn_Name', 'Prov', 'Clim_ID', 'decade', 'Year'])\n",
    "y = df['decade']\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "\n",
    "\n",
    "X_train_l, X_test_l,y_train_l,y_test_l = train_test_split(X,y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc16962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_l = StandardScaler()\n",
    "\n",
    "X_train_sc_l = sc_l.fit_transform(X_train_l)\n",
    "X_test_sc_l = sc_l.transform(X_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "36db7973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.1694 - acc: 0.1918 - val_loss: 2.0957 - val_acc: 0.2264\n",
      "Epoch 2/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.0756 - acc: 0.2335 - val_loss: 2.0352 - val_acc: 0.2547\n",
      "Epoch 3/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.0115 - acc: 0.2628 - val_loss: 1.9861 - val_acc: 0.2784\n",
      "Epoch 4/30\n",
      "2495/2495 [==============================] - 12s 5ms/step - loss: 1.9505 - acc: 0.2911 - val_loss: 1.9394 - val_acc: 0.2979\n",
      "Epoch 5/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.9029 - acc: 0.3126 - val_loss: 1.9087 - val_acc: 0.3104\n",
      "Epoch 6/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.8620 - acc: 0.3283 - val_loss: 1.8854 - val_acc: 0.3200\n",
      "Epoch 7/30\n",
      "2495/2495 [==============================] - 12s 5ms/step - loss: 1.8268 - acc: 0.3425 - val_loss: 1.8648 - val_acc: 0.3288\n",
      "Epoch 8/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7988 - acc: 0.3524 - val_loss: 1.8546 - val_acc: 0.3332\n",
      "Epoch 9/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7742 - acc: 0.3616 - val_loss: 1.8438 - val_acc: 0.3376\n",
      "Epoch 10/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7530 - acc: 0.3695 - val_loss: 1.8272 - val_acc: 0.3440\n",
      "Epoch 11/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7302 - acc: 0.3781 - val_loss: 1.8267 - val_acc: 0.3462\n",
      "Epoch 12/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7150 - acc: 0.3845 - val_loss: 1.8181 - val_acc: 0.3492\n",
      "Epoch 13/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6961 - acc: 0.3926 - val_loss: 1.8105 - val_acc: 0.3536\n",
      "Epoch 14/30\n",
      "2495/2495 [==============================] - 12s 5ms/step - loss: 1.6800 - acc: 0.3977 - val_loss: 1.8054 - val_acc: 0.3565\n",
      "Epoch 15/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6658 - acc: 0.4032 - val_loss: 1.8050 - val_acc: 0.3571\n",
      "Epoch 16/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6542 - acc: 0.4074 - val_loss: 1.8002 - val_acc: 0.3613\n",
      "Epoch 17/30\n",
      "2495/2495 [==============================] - 12s 5ms/step - loss: 1.6396 - acc: 0.4118 - val_loss: 1.8046 - val_acc: 0.3608\n",
      "Epoch 18/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6301 - acc: 0.4175 - val_loss: 1.7987 - val_acc: 0.3624\n",
      "Epoch 19/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6139 - acc: 0.4220 - val_loss: 1.8040 - val_acc: 0.3623\n",
      "Epoch 20/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6029 - acc: 0.4267 - val_loss: 1.7966 - val_acc: 0.3663\n",
      "Epoch 21/30\n",
      "2495/2495 [==============================] - 12s 5ms/step - loss: 1.5969 - acc: 0.4275 - val_loss: 1.8022 - val_acc: 0.3662\n",
      "Epoch 22/30\n",
      "2495/2495 [==============================] - 12s 5ms/step - loss: 1.5869 - acc: 0.4323 - val_loss: 1.8028 - val_acc: 0.3681\n",
      "Epoch 23/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5786 - acc: 0.4344 - val_loss: 1.7926 - val_acc: 0.3710\n",
      "Epoch 24/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5670 - acc: 0.4397 - val_loss: 1.8049 - val_acc: 0.3685\n",
      "Epoch 25/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5592 - acc: 0.4431 - val_loss: 1.8049 - val_acc: 0.3696\n",
      "Epoch 26/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5502 - acc: 0.4453 - val_loss: 1.8006 - val_acc: 0.3705\n",
      "Epoch 27/30\n",
      "2495/2495 [==============================] - 12s 5ms/step - loss: 1.5422 - acc: 0.4478 - val_loss: 1.8062 - val_acc: 0.3698\n",
      "Epoch 28/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5354 - acc: 0.4518 - val_loss: 1.8076 - val_acc: 0.3717\n",
      "Epoch 29/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5274 - acc: 0.4542 - val_loss: 1.8122 - val_acc: 0.3699\n",
      "Epoch 30/30\n",
      "2495/2495 [==============================] - 12s 5ms/step - loss: 1.5223 - acc: 0.4556 - val_loss: 1.8145 - val_acc: 0.3726\n"
     ]
    }
   ],
   "source": [
    "# creates a model using the new feature 'LxL'\n",
    "nn3= Sequential()\n",
    "# 1st hidden layer\n",
    "nn3.add(Dense(512, input_dim=X_train_sc_l.shape[1], activation='relu'))\n",
    "nn3.add(Dense(512, activation='relu'))\n",
    "nn3.add(Dense(512, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn3.add(Dense(11, activation='softmax'))\n",
    "\n",
    "# compiles model\n",
    "nn3.compile(loss ='categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
    "\n",
    "results3 = nn3.fit(X_train_sc_l, y_train_l,\n",
    "                    batch_size=256,\n",
    "                    epochs=30,\n",
    "                    validation_data=(X_test_sc_l,y_test_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "33ac143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 2.1678 - acc: 0.1926 - val_loss: 2.0956 - val_acc: 0.2257\n",
      "Epoch 2/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 2.0759 - acc: 0.2330 - val_loss: 2.0427 - val_acc: 0.2483\n",
      "Epoch 3/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 2.0115 - acc: 0.2647 - val_loss: 1.9810 - val_acc: 0.2781\n",
      "Epoch 4/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.9505 - acc: 0.2916 - val_loss: 1.9389 - val_acc: 0.2992\n",
      "Epoch 5/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.9030 - acc: 0.3120 - val_loss: 1.9060 - val_acc: 0.3111\n",
      "Epoch 6/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.8620 - acc: 0.3283 - val_loss: 1.8911 - val_acc: 0.3171\n",
      "Epoch 7/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.8306 - acc: 0.3400 - val_loss: 1.8612 - val_acc: 0.3297\n",
      "Epoch 8/30\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.7990 - acc: 0.3518 - val_loss: 1.8450 - val_acc: 0.3377\n",
      "Epoch 9/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7749 - acc: 0.3622 - val_loss: 1.8394 - val_acc: 0.3403\n",
      "Epoch 10/30\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.7507 - acc: 0.3718 - val_loss: 1.8205 - val_acc: 0.3481\n",
      "Epoch 11/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.7318 - acc: 0.3777 - val_loss: 1.8186 - val_acc: 0.3498\n",
      "Epoch 12/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.7111 - acc: 0.3859 - val_loss: 1.8130 - val_acc: 0.3523\n",
      "Epoch 13/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6938 - acc: 0.3922 - val_loss: 1.8047 - val_acc: 0.3553\n",
      "Epoch 14/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.6788 - acc: 0.3987 - val_loss: 1.8055 - val_acc: 0.3562\n",
      "Epoch 15/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6660 - acc: 0.4035 - val_loss: 1.7969 - val_acc: 0.3607\n",
      "Epoch 16/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6510 - acc: 0.4085 - val_loss: 1.7949 - val_acc: 0.3626\n",
      "Epoch 17/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.6383 - acc: 0.4135 - val_loss: 1.7997 - val_acc: 0.3631\n",
      "Epoch 18/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6241 - acc: 0.4183 - val_loss: 1.8007 - val_acc: 0.3629\n",
      "Epoch 19/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.6136 - acc: 0.4223 - val_loss: 1.7999 - val_acc: 0.3638\n",
      "Epoch 20/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.6041 - acc: 0.4259 - val_loss: 1.7962 - val_acc: 0.3678\n",
      "Epoch 21/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.5923 - acc: 0.4302 - val_loss: 1.7949 - val_acc: 0.3677\n",
      "Epoch 22/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5813 - acc: 0.4345 - val_loss: 1.7973 - val_acc: 0.3670\n",
      "Epoch 23/30\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.5731 - acc: 0.4379 - val_loss: 1.7918 - val_acc: 0.3690\n",
      "Epoch 24/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5644 - acc: 0.4405 - val_loss: 1.7935 - val_acc: 0.3718\n",
      "Epoch 25/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5573 - acc: 0.4431 - val_loss: 1.7979 - val_acc: 0.3700\n",
      "Epoch 26/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.5488 - acc: 0.4461 - val_loss: 1.8003 - val_acc: 0.3717\n",
      "Epoch 27/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5395 - acc: 0.4492 - val_loss: 1.7996 - val_acc: 0.3732\n",
      "Epoch 28/30\n",
      "2495/2495 [==============================] - 14s 5ms/step - loss: 1.5321 - acc: 0.4524 - val_loss: 1.8013 - val_acc: 0.3719\n",
      "Epoch 29/30\n",
      "2495/2495 [==============================] - 13s 5ms/step - loss: 1.5237 - acc: 0.4550 - val_loss: 1.8001 - val_acc: 0.3738\n",
      "Epoch 30/30\n",
      "2495/2495 [==============================] - 14s 6ms/step - loss: 1.5141 - acc: 0.4577 - val_loss: 1.8093 - val_acc: 0.3741\n"
     ]
    }
   ],
   "source": [
    "# creates our model using the origonal features (lacks 'lxL')\n",
    "nn= Sequential()\n",
    "# hidden layers\n",
    "nn.add(Dense(512, input_dim=X_train_sc.shape[1], activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "nn.add(Dense(512, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(Dense(11, activation='softmax'))\n",
    "\n",
    "\n",
    "#compiles model\n",
    "nn.compile(loss ='categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
    "\n",
    "results = nn.fit(X_train_sc, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=30,\n",
    "                    validation_data=(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c85b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
