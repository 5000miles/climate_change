{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2814e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8faec6d",
   "metadata": {},
   "source": [
    "# Building a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0901faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a function to get thge station data from a csv, and turns it into a dataframe. \n",
    "def process_data(file):\n",
    "    \n",
    "    df1 = pd.read_csv(file, skiprows=30)\n",
    "    df1.drop(columns = ['S_G', 'BS', 'DwBS', 'BS%'], inplace = True)\n",
    "    df1['Year'] = int(file.split('_')[-2])\n",
    "    df1['Month'] = int(file.split('_')[-1].split('.')[0])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2215836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Original_Canada_data/Canada1917-2017/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Grabs the data from each csv. \n",
    "canada_df_list = []\n",
    "path = './data/Original_Canada_data/Canada1917-2017/'\n",
    "for file in os.listdir(path):\n",
    "    try:\n",
    "        canada_df_list.append(process_data(path + file))\n",
    "    except:\n",
    "        print(path + file)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b87cea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Original_Canada_data/Canada_pt2/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Grabs the data from each csv in the second set of data. \n",
    "\n",
    "path = './data/Original_Canada_data/Canada_pt2/'\n",
    "for file in os.listdir(path):\n",
    "    try:\n",
    "        canada_df_list.append(process_data(path + file))\n",
    "    except:\n",
    "        print(path + file)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "010d4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatieates all the dataframes in the canada_df_list inro one df\n",
    "canada_df_raw = pd.concat(canada_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "115b3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_df = canada_df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b541a75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stn_Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Tm</th>\n",
       "      <th>DwTm</th>\n",
       "      <th>D</th>\n",
       "      <th>Tx</th>\n",
       "      <th>DwTx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>...</th>\n",
       "      <th>S%N</th>\n",
       "      <th>P</th>\n",
       "      <th>DwP</th>\n",
       "      <th>P%N</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Clim_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEAR CREEK</td>\n",
       "      <td>48.500</td>\n",
       "      <td>-124.000</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010720</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEAVER LAKE</td>\n",
       "      <td>48.500</td>\n",
       "      <td>-123.350</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010774</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COWICHAN</td>\n",
       "      <td>48.417</td>\n",
       "      <td>-123.700</td>\n",
       "      <td>BC</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>517.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012008</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COWICHAN BAY CHERRY POINT</td>\n",
       "      <td>48.711</td>\n",
       "      <td>-123.557</td>\n",
       "      <td>BC</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>516.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012010</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOLDSTREAM LAKE</td>\n",
       "      <td>48.450</td>\n",
       "      <td>-123.550</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013240</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Stn_Name     Lat     Long Prov   Tm  DwTm   D    Tx  DwTx  \\\n",
       "0                 BEAR CREEK  48.500 -124.000   BC  NaN   NaN NaN   NaN   NaN   \n",
       "1                BEAVER LAKE  48.500 -123.350   BC  NaN   NaN NaN   NaN   NaN   \n",
       "2                   COWICHAN  48.417 -123.700   BC  1.3   0.0 NaN  10.0   0.0   \n",
       "3  COWICHAN BAY CHERRY POINT  48.711 -123.557   BC  1.3   0.0 NaN  10.6   0.0   \n",
       "4            GOLDSTREAM LAKE  48.450 -123.550   BC  NaN   NaN NaN   NaN   NaN   \n",
       "\n",
       "     Tn  ...  S%N      P  DwP  P%N    Pd    HDD  CDD  Clim_ID  Year  Month  \n",
       "0   NaN  ...  NaN  415.3  0.0  NaN  23.0    NaN  NaN  1010720  1917      1  \n",
       "1   NaN  ...  NaN  122.5  0.0  NaN  17.0    NaN  NaN  1010774  1917      1  \n",
       "2 -13.9  ...  NaN  114.7  0.0  NaN  13.0  517.4  0.0  1012008  1917      1  \n",
       "3 -13.9  ...  NaN   87.7  0.0  NaN   9.0  516.6  0.0  1012010  1917      1  \n",
       "4   NaN  ...  NaN  223.5  0.0  NaN  18.0    NaN  NaN  1013240  1917      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canada_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adcf2af",
   "metadata": {},
   "source": [
    "# Clean New Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebfe8483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stn_Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Tm</th>\n",
       "      <th>DwTm</th>\n",
       "      <th>D</th>\n",
       "      <th>Tx</th>\n",
       "      <th>DwTx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>...</th>\n",
       "      <th>S%N</th>\n",
       "      <th>P</th>\n",
       "      <th>DwP</th>\n",
       "      <th>P%N</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Clim_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABITIBI POST</td>\n",
       "      <td>48.717</td>\n",
       "      <td>-79.367</td>\n",
       "      <td>QC</td>\n",
       "      <td>-19.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1164.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7090050</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGASSIZ CDA</td>\n",
       "      <td>49.243</td>\n",
       "      <td>-121.760</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>...</td>\n",
       "      <td>406</td>\n",
       "      <td>256.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>20.0</td>\n",
       "      <td>549.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100120</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALBERNI BEAVER CREEK</td>\n",
       "      <td>49.367</td>\n",
       "      <td>-124.933</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>542.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1030180</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALERT BAY</td>\n",
       "      <td>50.583</td>\n",
       "      <td>-126.933</td>\n",
       "      <td>BC</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>460.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020270</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALIX</td>\n",
       "      <td>52.383</td>\n",
       "      <td>-113.167</td>\n",
       "      <td>AB</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1036.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3020120</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835893</th>\n",
       "      <td>YOHIN</td>\n",
       "      <td>61.242</td>\n",
       "      <td>-123.742</td>\n",
       "      <td>NT</td>\n",
       "      <td>-16.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-39.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2204300</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835894</th>\n",
       "      <td>YOHO PARK</td>\n",
       "      <td>51.443</td>\n",
       "      <td>-116.345</td>\n",
       "      <td>BC</td>\n",
       "      <td>-14.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1010.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11790J1</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835895</th>\n",
       "      <td>YORKTON</td>\n",
       "      <td>51.265</td>\n",
       "      <td>-102.464</td>\n",
       "      <td>SK</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>969.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4019073</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835896</th>\n",
       "      <td>YORKTON</td>\n",
       "      <td>51.265</td>\n",
       "      <td>-102.462</td>\n",
       "      <td>SK</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>887.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4019075</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835897</th>\n",
       "      <td>ZEBALLOS MURAUDE CREEK</td>\n",
       "      <td>50.053</td>\n",
       "      <td>-126.779</td>\n",
       "      <td>BC</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>451.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1039035</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1835898 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Stn_Name     Lat     Long Prov    Tm  DwTm    D    Tx  \\\n",
       "0                  ABITIBI POST  48.717  -79.367   QC -19.6   0.0  NaN   1.7   \n",
       "1                   AGASSIZ CDA  49.243 -121.760   BC   0.3   0.0 -3.1   8.9   \n",
       "2          ALBERNI BEAVER CREEK  49.367 -124.933   BC   0.5   0.0  NaN   9.4   \n",
       "3                     ALERT BAY  50.583 -126.933   BC   3.2   0.0  NaN   8.9   \n",
       "4                          ALIX  52.383 -113.167   AB -15.4   0.0  NaN   6.7   \n",
       "...                         ...     ...      ...  ...   ...   ...  ...   ...   \n",
       "1835893                   YOHIN  61.242 -123.742   NT -16.1  16.0  NaN  12.5   \n",
       "1835894               YOHO PARK  51.443 -116.345   BC -14.6   0.0  NaN  -1.8   \n",
       "1835895                 YORKTON  51.265 -102.464   SK -13.3   0.0  NaN   4.2   \n",
       "1835896                 YORKTON  51.265 -102.462   SK -13.7   3.0  NaN   4.1   \n",
       "1835897  ZEBALLOS MURAUDE CREEK  50.053 -126.779   BC   3.4   0.0  NaN  16.5   \n",
       "\n",
       "         DwTx    Tn  ...  S%N      P  DwP  P%N    Pd     HDD  CDD  Clim_ID  \\\n",
       "0         0.0 -38.3  ...  NaN   22.9  0.0  NaN   5.0  1164.5  0.0  7090050   \n",
       "1         0.0 -18.3  ...  406  256.5  0.0  107  20.0   549.4  0.0  1100120   \n",
       "2         0.0 -16.7  ...  NaN  136.1  0.0  NaN  13.0   542.1  0.0  1030180   \n",
       "3         0.0 -11.1  ...  NaN    186  0.0  NaN  21.0   460.1  0.0  1020270   \n",
       "4         0.0 -47.2  ...  NaN     42  0.0  NaN   9.0  1036.2  0.0  3020120   \n",
       "...       ...   ...  ...  ...    ...  ...  ...   ...     ...  ...      ...   \n",
       "1835893  15.0 -39.5  ...  NaN    NaN  NaN  NaN   NaN   510.9  0.0  2204300   \n",
       "1835894   0.0 -34.4  ...  NaN   10.8  0.0  NaN   4.0  1010.2  0.0  11790J1   \n",
       "1835895   0.0 -35.9  ...  NaN    8.2  0.0  NaN   3.0   969.7  0.0  4019073   \n",
       "1835896   3.0 -35.5  ...  NaN      0  3.0  NaN   0.0   887.3  0.0  4019075   \n",
       "1835897   0.0  -5.0  ...  NaN  105.1  0.0  NaN  10.0   451.8  0.0  1039035   \n",
       "\n",
       "         Year  Month  \n",
       "0        1917      1  \n",
       "1        1917      1  \n",
       "2        1917      1  \n",
       "3        1917      1  \n",
       "4        1917      1  \n",
       "...       ...    ...  \n",
       "1835893  2017     12  \n",
       "1835894  2017     12  \n",
       "1835895  2017     12  \n",
       "1835896  2017     12  \n",
       "1835897  2017     12  \n",
       "\n",
       "[1835898 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorders the index to be more intuitve off of month and year.\n",
    "canada_df = canada_df_raw.sort_values(['Year','Month','Stn_Name'],ignore_index=True)\n",
    "canada_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7aba1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Tm</th>\n",
       "      <th>DwTm</th>\n",
       "      <th>D</th>\n",
       "      <th>Tx</th>\n",
       "      <th>DwTx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>DwTn</th>\n",
       "      <th>S</th>\n",
       "      <th>DwS</th>\n",
       "      <th>DwP</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.835478e+06</td>\n",
       "      <td>1.835478e+06</td>\n",
       "      <td>1.521092e+06</td>\n",
       "      <td>1.521092e+06</td>\n",
       "      <td>571209.000000</td>\n",
       "      <td>1.525837e+06</td>\n",
       "      <td>1.525837e+06</td>\n",
       "      <td>1.525529e+06</td>\n",
       "      <td>1.525529e+06</td>\n",
       "      <td>1.666018e+06</td>\n",
       "      <td>1.666018e+06</td>\n",
       "      <td>1.776131e+06</td>\n",
       "      <td>1.776132e+06</td>\n",
       "      <td>1.521092e+06</td>\n",
       "      <td>1.521092e+06</td>\n",
       "      <td>1.835898e+06</td>\n",
       "      <td>1.835898e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.004811e+01</td>\n",
       "      <td>-9.620463e+01</td>\n",
       "      <td>3.838740e+00</td>\n",
       "      <td>1.004419e+00</td>\n",
       "      <td>-0.232763</td>\n",
       "      <td>1.853468e+01</td>\n",
       "      <td>8.351692e-01</td>\n",
       "      <td>-1.082070e+01</td>\n",
       "      <td>8.089155e-01</td>\n",
       "      <td>1.438459e+01</td>\n",
       "      <td>4.770020e-01</td>\n",
       "      <td>6.661902e-01</td>\n",
       "      <td>8.730172e+00</td>\n",
       "      <td>4.231030e+02</td>\n",
       "      <td>8.200875e+00</td>\n",
       "      <td>1.975797e+03</td>\n",
       "      <td>6.517412e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.142950e+00</td>\n",
       "      <td>2.283881e+01</td>\n",
       "      <td>1.140346e+01</td>\n",
       "      <td>3.533881e+00</td>\n",
       "      <td>2.402592</td>\n",
       "      <td>1.093696e+01</td>\n",
       "      <td>3.175385e+00</td>\n",
       "      <td>1.431251e+01</td>\n",
       "      <td>3.150751e+00</td>\n",
       "      <td>2.563321e+01</td>\n",
       "      <td>2.830718e+00</td>\n",
       "      <td>3.101179e+00</td>\n",
       "      <td>4.763549e+00</td>\n",
       "      <td>3.289856e+02</td>\n",
       "      <td>2.069718e+01</td>\n",
       "      <td>2.436243e+01</td>\n",
       "      <td>3.410709e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.410000e+02</td>\n",
       "      <td>-5.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-23.300000</td>\n",
       "      <td>-5.210000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.300000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.917000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.643300e+01</td>\n",
       "      <td>-1.165180e+02</td>\n",
       "      <td>-4.300000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>9.800000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.373000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.960000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.941700e+01</td>\n",
       "      <td>-1.007500e+02</td>\n",
       "      <td>5.600000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>3.617000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.978000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.183300e+01</td>\n",
       "      <td>-7.518300e+01</td>\n",
       "      <td>1.330000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.980000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>6.569000e+02</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>1.995000e+03</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.251800e+01</td>\n",
       "      <td>8.100000e+00</td>\n",
       "      <td>2.790000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.940000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>7.259000e+02</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.089000e+03</td>\n",
       "      <td>2.726000e+02</td>\n",
       "      <td>2.017000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Lat          Long            Tm          DwTm              D  \\\n",
       "count  1.835478e+06  1.835478e+06  1.521092e+06  1.521092e+06  571209.000000   \n",
       "mean   5.004811e+01 -9.620463e+01  3.838740e+00  1.004419e+00      -0.232763   \n",
       "std    5.142950e+00  2.283881e+01  1.140346e+01  3.533881e+00       2.402592   \n",
       "min    0.000000e+00 -1.410000e+02 -5.000000e+01  0.000000e+00     -23.300000   \n",
       "25%    4.643300e+01 -1.165180e+02 -4.300000e+00  0.000000e+00      -1.400000   \n",
       "50%    4.941700e+01 -1.007500e+02  5.600000e+00  0.000000e+00      -0.100000   \n",
       "75%    5.183300e+01 -7.518300e+01  1.330000e+01  0.000000e+00       1.100000   \n",
       "max    8.251800e+01  8.100000e+00  2.790000e+01  3.000000e+01      16.700000   \n",
       "\n",
       "                 Tx          DwTx            Tn          DwTn             S  \\\n",
       "count  1.525837e+06  1.525837e+06  1.525529e+06  1.525529e+06  1.666018e+06   \n",
       "mean   1.853468e+01  8.351692e-01 -1.082070e+01  8.089155e-01  1.438459e+01   \n",
       "std    1.093696e+01  3.175385e+00  1.431251e+01  3.150751e+00  2.563321e+01   \n",
       "min   -5.210000e+01  0.000000e+00 -6.300000e+01  0.000000e+00 -3.000000e+00   \n",
       "25%    9.800000e+00  0.000000e+00 -2.200000e+01  0.000000e+00  0.000000e+00   \n",
       "50%    2.000000e+01  0.000000e+00 -6.500000e+00  0.000000e+00  8.000000e-01   \n",
       "75%    2.800000e+01  0.000000e+00  6.000000e-01  0.000000e+00  1.980000e+01   \n",
       "max    5.000000e+01  3.000000e+01  2.940000e+01  3.000000e+01  7.259000e+02   \n",
       "\n",
       "                DwS           DwP            Pd           HDD           CDD  \\\n",
       "count  1.666018e+06  1.776131e+06  1.776132e+06  1.521092e+06  1.521092e+06   \n",
       "mean   4.770020e-01  6.661902e-01  8.730172e+00  4.231030e+02  8.200875e+00   \n",
       "std    2.830718e+00  3.101179e+00  4.763549e+00  3.289856e+02  2.069718e+01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  5.000000e+00  1.373000e+02  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  8.000000e+00  3.617000e+02  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  1.200000e+01  6.569000e+02  3.500000e+00   \n",
       "max    3.000000e+01  3.000000e+01  3.100000e+01  2.089000e+03  2.726000e+02   \n",
       "\n",
       "               Year         Month  \n",
       "count  1.835898e+06  1.835898e+06  \n",
       "mean   1.975797e+03  6.517412e+00  \n",
       "std    2.436243e+01  3.410709e+00  \n",
       "min    1.917000e+03  1.000000e+00  \n",
       "25%    1.960000e+03  4.000000e+00  \n",
       "50%    1.978000e+03  7.000000e+00  \n",
       "75%    1.995000e+03  9.000000e+00  \n",
       "max    2.017000e+03  1.200000e+01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows a table that gives basic statistical data, for each colunn that has numerical data.\n",
    "canada_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d7efa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stn_Name          0\n",
       "Lat             420\n",
       "Long            420\n",
       "Prov              0\n",
       "Tm           314806\n",
       "DwTm         314806\n",
       "D           1264689\n",
       "Tx           310061\n",
       "DwTx         310061\n",
       "Tn           310369\n",
       "DwTn         310369\n",
       "S            169880\n",
       "DwS          169880\n",
       "S%N         1403908\n",
       "P             59766\n",
       "DwP           59767\n",
       "P%N         1240210\n",
       "Pd            59766\n",
       "HDD          314806\n",
       "CDD          314806\n",
       "Clim_ID           0\n",
       "Year              0\n",
       "Month             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts all null values in each column \n",
    "canada_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47f6dce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stn_Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Tm</th>\n",
       "      <th>DwTm</th>\n",
       "      <th>D</th>\n",
       "      <th>Tx</th>\n",
       "      <th>DwTx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>...</th>\n",
       "      <th>S%N</th>\n",
       "      <th>P</th>\n",
       "      <th>DwP</th>\n",
       "      <th>P%N</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Clim_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALKALI LAKE</td>\n",
       "      <td>51.783</td>\n",
       "      <td>-122.283</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1090335</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANTICOSTI HEATH POINT</td>\n",
       "      <td>49.100</td>\n",
       "      <td>-61.700</td>\n",
       "      <td>QC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7050198</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ANTICOSTI WEST POINT</td>\n",
       "      <td>49.867</td>\n",
       "      <td>-64.533</td>\n",
       "      <td>QC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7050210</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BASHAW</td>\n",
       "      <td>52.683</td>\n",
       "      <td>-112.867</td>\n",
       "      <td>AB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3010535</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BEAR CREEK</td>\n",
       "      <td>48.500</td>\n",
       "      <td>-124.000</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010720</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835834</th>\n",
       "      <td>VICTORIA FRANCIS PARK</td>\n",
       "      <td>48.476</td>\n",
       "      <td>-123.443</td>\n",
       "      <td>BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018605</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835855</th>\n",
       "      <td>WAWA A</td>\n",
       "      <td>47.967</td>\n",
       "      <td>-84.786</td>\n",
       "      <td>ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6059407</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835867</th>\n",
       "      <td>WHITECOURT A</td>\n",
       "      <td>54.144</td>\n",
       "      <td>-115.787</td>\n",
       "      <td>AB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3067373</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835878</th>\n",
       "      <td>WINNIPEG CHARLESWOOD 2</td>\n",
       "      <td>49.850</td>\n",
       "      <td>-97.273</td>\n",
       "      <td>MB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5023225</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835886</th>\n",
       "      <td>WROXETER</td>\n",
       "      <td>43.863</td>\n",
       "      <td>-81.152</td>\n",
       "      <td>ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6129660</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313897 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Stn_Name     Lat     Long Prov  Tm  DwTm   D    Tx  \\\n",
       "5                   ALKALI LAKE  51.783 -122.283   BC NaN   NaN NaN   NaN   \n",
       "13        ANTICOSTI HEATH POINT  49.100  -61.700   QC NaN   NaN NaN   NaN   \n",
       "15         ANTICOSTI WEST POINT  49.867  -64.533   QC NaN   NaN NaN   NaN   \n",
       "34                       BASHAW  52.683 -112.867   AB NaN   NaN NaN   NaN   \n",
       "38                   BEAR CREEK  48.500 -124.000   BC NaN   NaN NaN   NaN   \n",
       "...                         ...     ...      ...  ...  ..   ...  ..   ...   \n",
       "1835834   VICTORIA FRANCIS PARK  48.476 -123.443   BC NaN   NaN NaN   NaN   \n",
       "1835855                  WAWA A  47.967  -84.786   ON NaN   NaN NaN  16.4   \n",
       "1835867            WHITECOURT A  54.144 -115.787   AB NaN   NaN NaN   9.2   \n",
       "1835878  WINNIPEG CHARLESWOOD 2  49.850  -97.273   MB NaN   NaN NaN   NaN   \n",
       "1835886                WROXETER  43.863  -81.152   ON NaN   NaN NaN   NaN   \n",
       "\n",
       "         DwTx  Tn  ...  S%N      P   DwP  P%N    Pd  HDD CDD  Clim_ID  Year  \\\n",
       "5         NaN NaN  ...  NaN   25.2   0.0  NaN   9.0  NaN NaN  1090335  1917   \n",
       "13        NaN NaN  ...  NaN    131   0.0  NaN  10.0  NaN NaN  7050198  1917   \n",
       "15        NaN NaN  ...  NaN  135.8   0.0  NaN  17.0  NaN NaN  7050210  1917   \n",
       "34        NaN NaN  ...  NaN   35.6   0.0  NaN   5.0  NaN NaN  3010535  1917   \n",
       "38        NaN NaN  ...  NaN  415.3   0.0  NaN  23.0  NaN NaN  1010720  1917   \n",
       "...       ...  ..  ...  ...    ...   ...  ...   ...  ...  ..      ...   ...   \n",
       "1835834   NaN NaN  ...  NaN  132.8   3.0  NaN  11.0  NaN NaN  1018605  2017   \n",
       "1835855   7.0 NaN  ...  NaN    NaN   NaN  NaN   NaN  NaN NaN  6059407  2017   \n",
       "1835867   2.0 NaN  ...  NaN    NaN   NaN  NaN   NaN  NaN NaN  3067373  2017   \n",
       "1835878   NaN NaN  ...  NaN   15.6   0.0  NaN   5.0  NaN NaN  5023225  2017   \n",
       "1835886   NaN NaN  ...  NaN   43.6  11.0  NaN  14.0  NaN NaN  6129660  2017   \n",
       "\n",
       "         Month  \n",
       "5            1  \n",
       "13           1  \n",
       "15           1  \n",
       "34           1  \n",
       "38           1  \n",
       "...        ...  \n",
       "1835834     12  \n",
       "1835855     12  \n",
       "1835867     12  \n",
       "1835878     12  \n",
       "1835886     12  \n",
       "\n",
       "[313897 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This shows all the rows with a missing 'Tm' valure and, a missisng 'Tn' or 'Tx' value.\n",
    "# This does not give enough temp data for us to fill in the 'Tm' value for that row.\n",
    "canada_df[(canada_df['Tm'] != canada_df['Tm']) & \n",
    "          ((canada_df['Tx'] != canada_df['Tx']) | (canada_df['Tn'] != canada_df['Tn']))\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4874cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This drops all rows that have a missing 'Tm' value\n",
    "canada_df = canada_df.drop(canada_df[(canada_df['Tm'] != canada_df['Tm']) & \n",
    "                                     ((canada_df['Tx'] != canada_df['Tx']) |\n",
    "                                      (canada_df['Tn'] != canada_df['Tn']))].index\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f85cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'S' values into a list\n",
    "missing_S_idx = list(canada_df[canada_df['S'] != canada_df['S']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8278d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'S' by station and month\n",
    "snow_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fe1d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'S' with the avgearge snowfall based on month and station\n",
    "S_group =  canada_df.groupby('Month')['S'].mean()\n",
    "for idx in missing_S_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_S = snow_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_S == avg_S:\n",
    "                canada_df.at[idx,'S'] = avg_S\n",
    "          \n",
    "        # some staions have null values for a month , so using the average snowfallin the entire dataframe for that month \n",
    "            elif avg_S != avg_S:\n",
    "                canada_df.at[idx,'S'] = S_group[month]\n",
    "                \n",
    "# some stations have no data for 'S', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'S'] =S_group[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0bb01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'S' by station and month\n",
    "DwS_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'DwS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "899cef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'DwS' values into a list\n",
    "missing_DwS_idx = list(canada_df[canada_df['DwS'] != canada_df['DwS']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37941958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'DwS' with the avgearge based on month and station\n",
    "DwS_group = canada_df.groupby('Month')['DwS'].mean()\n",
    "for idx in missing_DwS_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_DwS = DwS_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_DwS == avg_DwS:\n",
    "                canada_df.at[idx,'DwS'] = avg_DwS\n",
    "          \n",
    "        # some staions have null values for a month , so using the average 'DwS in the entire dataframe for that month \n",
    "            elif avg_DwS != avg_DwS:\n",
    "                canada_df.at[idx,'DwS'] = DwS_group[month]\n",
    "                \n",
    "# some stations have no data for 'DwS', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'DwS'] =DwS_group[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6233ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the 'D' and 'P%N' columns since the amount of  missing data\n",
    "canada_df.drop(columns = ['D', 'P%N'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05376972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the 'S%N' columns since the amount of  missing data\n",
    "canada_df.drop(columns ='S%N', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "399b90b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stn_Name        0\n",
       "Lat             0\n",
       "Long            0\n",
       "Prov            0\n",
       "Tm            909\n",
       "DwTm          909\n",
       "Tx             40\n",
       "DwTx           40\n",
       "Tn             18\n",
       "DwTn           18\n",
       "S               0\n",
       "DwS             0\n",
       "P           52334\n",
       "DwP         52335\n",
       "Pd          52334\n",
       "HDD           909\n",
       "CDD           909\n",
       "Clim_ID         0\n",
       "Year            0\n",
       "Month           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canada_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16b8b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>DwP</th>\n",
       "      <th>Pd</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Clim_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8200150</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1411.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6020381</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6160465</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1022.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3030856</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1164.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4011090</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835856</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6049443</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835858</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>465.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1108824</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835860</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>650.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6119M51</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835868</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>899.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2101303</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835893</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2204300</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52334 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           P  DwP  Pd     HDD  CDD  Clim_ID  Year  Month\n",
       "16       NaN  NaN NaN   810.0  0.0  8200150  1917      1\n",
       "22       NaN  NaN NaN  1411.3  0.0  6020381  1917      1\n",
       "26       NaN  NaN NaN   937.0  0.0  6160465  1917      1\n",
       "61       NaN  NaN NaN  1022.8  0.0  3030856  1917      1\n",
       "68       NaN  NaN NaN  1164.9  0.0  4011090  1917      1\n",
       "...      ...  ...  ..     ...  ...      ...   ...    ...\n",
       "1835856  NaN  NaN NaN   893.3  0.0  6049443  2017     12\n",
       "1835858  NaN  NaN NaN   465.1  0.0  1108824  2017     12\n",
       "1835860  NaN  NaN NaN   650.4  0.0  6119M51  2017     12\n",
       "1835868  NaN  NaN NaN   899.6  0.0  2101303  2017     12\n",
       "1835893  NaN  NaN NaN   510.9  0.0  2204300  2017     12\n",
       "\n",
       "[52334 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The values with missing precicpitation data are missing the data from the relevent rows also.\n",
    "canada_df[(canada_df['P']!=canada_df['P'])].loc[:,'P':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "252805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treats '######' as a null value for the column 'P'\n",
    "canada_df['P'] = np.where(canada_df['P'] == '######',np.nan,canada_df['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffe39825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the data type of 'P' to float\n",
    "canada_df['P'] = canada_df['P'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3675d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'P' values into a list\n",
    "missing_P_idx = list(canada_df[canada_df['P'] != canada_df['P']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4959fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'P' by station and month\n",
    "P_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28ad6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'P' with the avgearge based on month and station\n",
    "P_group = canada_df.groupby('Month')['P'].mean()\n",
    "for idx in missing_P_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_P = P_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_P == avg_P:\n",
    "                canada_df.at[idx,'P'] = avg_P\n",
    "          \n",
    "        # some staions have null values for a month , so using the average 'P in the entire dataframe for that month \n",
    "            elif avg_P != avg_P:\n",
    "                canada_df.at[idx,'P'] = P_group[month]\n",
    "                \n",
    "# some stations have no data for 'P', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'P'] =P_group[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57925b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'Pd' values into a list\n",
    "missing_Pd_idx = list(canada_df[canada_df['Pd'] != canada_df['Pd']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d62d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'Pd' by station and month\n",
    "Pd_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'Pd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c66e4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'Pd' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_Pd_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_Pd = Pd_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_Pd == avg_Pd:\n",
    "                canada_df.at[idx,'Pd'] = avg_Pd\n",
    "          \n",
    "        # some staions have null values for a month , so using the average 'Pd in the entire dataframe for that month \n",
    "            elif avg_Pd != avg_Pd:\n",
    "                canada_df.at[idx,'Pd'] = canada_df.groupby('Month')['Pd'].mean()[month]\n",
    "                \n",
    "# some stations have no data for 'Pd', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'Pd'] =canada_df.groupby('Month')['Pd'].mean()[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff7ad20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the indexs of the rows with missing 'DwP' values into a list\n",
    "missing_DwP_idx = list(canada_df[canada_df['DwP'] != canada_df['DwP']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c152933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'Pd' by station and month\n",
    "DwP_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'DwP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5f2d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'DwP' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_DwP_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_DwP = DwP_pt.loc[station,month]    \n",
    "            \n",
    "            if avg_DwP == avg_DwP:\n",
    "                canada_df.at[idx,'DwP'] = avg_DwP\n",
    "          \n",
    "        # some staions have null values for a month , so using the average 'DwP in the entire dataframe for that month \n",
    "            elif avg_DwP != avg_DwP:\n",
    "                canada_df.at[idx,'DwP'] = canada_df.groupby('Month')['DwP'].mean()[month]\n",
    "                \n",
    "# some stations have no data for 'DwP', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'DwP'] =canada_df.groupby('Month')['DwP'].mean()[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45f014e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'Tm' value\n",
    "missing_Tm_idx = list(canada_df[canada_df['Tm'] != canada_df['Tm']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba022958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages out the high and low for the month to get the value for the missing monthly average \n",
    "for idx in missing_Tm_idx:\n",
    "    \n",
    "        canada_df.at[idx,'Tm'] = (canada_df.at[idx,'Tn'] + canada_df.at[idx,'Tx']) / 2\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4f54ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'DwTm' value\n",
    "missing_DwTm_idx = list(canada_df[canada_df['DwTm'] != canada_df['DwTm']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec1f034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces the missing 'DwTm' values with 0 \n",
    "for idx in missing_DwTm_idx:\n",
    "    \n",
    "        canada_df.at[idx,'DwTm'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c99707f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'DwTx' value\n",
    "missing_DwTx_idx = list(canada_df[canada_df['DwTx'] != canada_df['DwTx']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1982ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces the missing 'DwTx' values with 0 \n",
    "for idx in missing_DwTx_idx:\n",
    "    \n",
    "        canada_df.at[idx,'DwTx'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7418333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'Tx' value\n",
    "missing_Tx_idx = list(canada_df[canada_df['Tx'] != canada_df['Tx']].index)\n",
    "\n",
    "# Makes a pivot table showing the average 'Pd' by station and month\n",
    "Tx_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'Tx'))\n",
    "\n",
    "# Replaces missing values in 'Tx' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_Tx_idx:\n",
    "        station = canada_df.at[idx,'Stn_Name']\n",
    "        month = canada_df.at[idx,'Month']\n",
    "        avg_Tx = Tx_pt.loc[station,month]    \n",
    "            \n",
    "        canada_df.at[idx,'Tx'] = avg_Tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72c0b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'HDD' and 'CDD' values\n",
    "missing_HDD_idx = list(canada_df[(canada_df['HDD'] != canada_df['HDD']) & canada_df['CDD'] != canada_df['CDD']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90065482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'HDD' by station and month\n",
    "HDD_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'HDD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dff1a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a pivot table showing the average 'CDD' by station and month\n",
    "CDD_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'CDD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f66d5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing values in 'HDD' and \"CDD\" with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_HDD_idx:\n",
    "        try:\n",
    "            station = canada_df.at[idx,'Stn_Name']\n",
    "            month = canada_df.at[idx,'Month']\n",
    "            avg_HDD = HDD_pt.loc[station,month]    \n",
    "            avg_CDD = CDD_pt.loc[station,month]\n",
    "\n",
    "\n",
    "            if avg_HDD == avg_HDD:\n",
    "                canada_df.at[idx,'HDD'] = avg_HDD\n",
    "\n",
    "            elif avg_HDD != avg_HDD:\n",
    "                canada_df.at[idx,'HDD'] = canada_df.groupby('Month')['HDD'].mean()[month]\n",
    "\n",
    "\n",
    "            if avg_CDD == avg_CDD:\n",
    "                canada_df.at[idx,'CDD'] = avg_CDD\n",
    "\n",
    "            elif avg_CDD != avg_CDD:\n",
    "                canada_df.at[idx,'CDD'] = canada_df.groupby('Month')['CDD'].mean()[month]\n",
    "\n",
    "            # some stations have no data for 'HDD', or 'CDD', so using the average snowfallin the entire dataframe for that month \n",
    "        except:\n",
    "            canada_df.at[idx,'HDD'] =canada_df.groupby('Month')['HDD'].mean()[month]\n",
    "            canada_df.at[idx,'CDD'] =canada_df.groupby('Month')['CDD'].mean()[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59694696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'Tn' value\n",
    "missing_Tn_idx = list(canada_df[canada_df['Tn'] != canada_df['Tn']].index)\n",
    "\n",
    "# Makes a pivot table showing the average 'Pd' by station and month\n",
    "Tn_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'Tn'))\n",
    "\n",
    "# Replaces missing values in 'Tn' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_Tn_idx:\n",
    "        station = canada_df.at[idx,'Stn_Name']\n",
    "        month = canada_df.at[idx,'Month']\n",
    "        avg_Tn = Tn_pt.loc[station,month]    \n",
    "            \n",
    "        canada_df.at[idx,'Tn'] = avg_Tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a27c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of all indexs that have a missing 'DwTn' value\n",
    "missing_DwTn_idx = list(canada_df[canada_df['DwTn'] != canada_df['DwTn']].index)\n",
    "\n",
    "# Makes a pivot table showing the average 'Pd' by station and month\n",
    "DwTn_pt = pd.DataFrame(pd.pivot_table(canada_df, columns='Month', index='Stn_Name', values= 'DwTn'))\n",
    "\n",
    "# Replaces missing values in 'DwTn' with the avgearge based on month and station\n",
    "\n",
    "for idx in missing_DwTn_idx:\n",
    "        station = canada_df.at[idx,'Stn_Name']\n",
    "        month = canada_df.at[idx,'Month']\n",
    "        avg_DwTn = DwTn_pt.loc[station,month]    \n",
    "            \n",
    "        canada_df.at[idx,'DwTn'] = avg_DwTn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3047b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_df.to_csv('./data/canada_all_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9c193a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1522001, 20)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canada_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4921234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/canada_all_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2c1d6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1522001, 21)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9dda20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Unnamed: 0',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b92ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperates the dataframe into parts contains 100,000 rows each\n",
    "df1 = df.loc[:100_000,]\n",
    "\n",
    "df2 = df.loc[100_001:200_000,]\n",
    "\n",
    "df3 = df.loc[200_001:300_000,]\n",
    "\n",
    "df4 = df.loc[300_001:400_000,]\n",
    "\n",
    "df5 = df.loc[400_001:500_000,]\n",
    "\n",
    "df6 = df.loc[500_001:600_000,]\n",
    "\n",
    "df7 = df.loc[600_001:700_000,]\n",
    "\n",
    "df8 = df.loc[700_001:800_000,]\n",
    "\n",
    "df9 = df.loc[800_001:900_000,]\n",
    "\n",
    "df10 = df.loc[900_001:1_000_000,]\n",
    "\n",
    "df11 = df.loc[1_000_001:1_100_000,]\n",
    "\n",
    "df12= df.loc[1_100_001:1_200_000,]\n",
    "\n",
    "df13= df.loc[1_200_001:1_300_000,]\n",
    "\n",
    "df14= df.loc[1_300_001:1_400_000,]\n",
    "\n",
    "df15= df.loc[1_400_001:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "997a813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the dataframe as 15 different files\n",
    "df1.to_csv('./data/canada_all_df_pt1.csv', index=False)\n",
    "\n",
    "df2.to_csv('./data/canada_all_df_pt2.csv', index=False)\n",
    "\n",
    "df3.to_csv('./data/canada_all_df_pt3.csv', index=False)\n",
    "\n",
    "df4.to_csv('./data/canada_all_df_pt4.csv', index=False)\n",
    "\n",
    "df5.to_csv('./data/canada_all_df_pt5.csv', index=False)\n",
    "\n",
    "df6.to_csv('./data/canada_all_df_pt6.csv', index=False)\n",
    "\n",
    "df7.to_csv('./data/canada_all_df_pt7.csv', index=False)\n",
    "\n",
    "df8.to_csv('./data/canada_all_df_pt8.csv', index=False)\n",
    "\n",
    "df9.to_csv('./data/canada_all_df_pt9.csv', index=False)\n",
    "\n",
    "df10.to_csv('./data/canada_all_df_pt10.csv', index=False)\n",
    "\n",
    "df11.to_csv('./data/canada_all_df_pt11.csv', index=False)\n",
    "\n",
    "df12.to_csv('./data/canada_all_df_pt12.csv', index=False)\n",
    "\n",
    "df13.to_csv('./data/canada_all_df_pt13.csv', index=False)\n",
    "\n",
    "df14.to_csv('./data/canada_all_df_pt14.csv', index=False)\n",
    "\n",
    "df15.to_csv('./data/canada_all_df_pt15.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ae0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
