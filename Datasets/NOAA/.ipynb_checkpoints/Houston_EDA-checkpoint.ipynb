{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first:\n",
    " - Read in the CSV files, \n",
    " - Verify each has the same column length and column index, \n",
    " - Concatenate them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (3,42,43,49,51,95) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (42,49,51) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (41,42,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (41,42,43,46,52) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (41,42,43,46,49,52,55,56) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (3,19,25,26,27,28,29,31,32,34,36,37,41,42,43,44,46,49,50,52,54,56,58,59,61,69,71,72,88,95,96,97,98,99,100,101,102,103,104,105,106,107) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (3,19,25,26,27,28,29,30,31,32,33,41,42,43,46,48,49,50,51,52,53,55,56,58,59,61,69,71,72,82,88,95,96,97,98,99,100,101,102,103,104,105,106,107,111,112,113,114,115,116,117,118,119) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (30,31,41,42,43,51,56,60,62,88) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>BackupDirection</th>\n",
       "      <th>BackupDistance</th>\n",
       "      <th>BackupDistanceUnit</th>\n",
       "      <th>BackupElements</th>\n",
       "      <th>BackupElevation</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortDurationPrecipitationValue060</th>\n",
       "      <th>ShortDurationPrecipitationValue080</th>\n",
       "      <th>ShortDurationPrecipitationValue100</th>\n",
       "      <th>ShortDurationPrecipitationValue120</th>\n",
       "      <th>ShortDurationPrecipitationValue150</th>\n",
       "      <th>ShortDurationPrecipitationValue180</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>TStorms</th>\n",
       "      <th>WindEquipmentChangeDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99999912918</td>\n",
       "      <td>1948-07-01T00:00:00</td>\n",
       "      <td>SAO</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99999912918</td>\n",
       "      <td>1948-07-01T01:00:00</td>\n",
       "      <td>SAO</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99999912918</td>\n",
       "      <td>1948-07-01T02:00:00</td>\n",
       "      <td>SAO</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99999912918</td>\n",
       "      <td>1948-07-01T03:00:00</td>\n",
       "      <td>SAO</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99999912918</td>\n",
       "      <td>1948-07-01T04:00:00</td>\n",
       "      <td>SAO</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-06-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                 DATE REPORT_TYPE SOURCE  AWND  BackupDirection  \\\n",
       "0  99999912918  1948-07-01T00:00:00       SAO        E   NaN              NaN   \n",
       "1  99999912918  1948-07-01T01:00:00       SAO        E   NaN              NaN   \n",
       "2  99999912918  1948-07-01T02:00:00       SAO        E   NaN              NaN   \n",
       "3  99999912918  1948-07-01T03:00:00       SAO        E   NaN              NaN   \n",
       "4  99999912918  1948-07-01T04:00:00       SAO        E   NaN              NaN   \n",
       "\n",
       "   BackupDistance  BackupDistanceUnit  BackupElements  BackupElevation  ...  \\\n",
       "0             NaN                 NaN             NaN              NaN  ...   \n",
       "1             NaN                 NaN             NaN              NaN  ...   \n",
       "2             NaN                 NaN             NaN              NaN  ...   \n",
       "3             NaN                 NaN             NaN              NaN  ...   \n",
       "4             NaN                 NaN             NaN              NaN  ...   \n",
       "\n",
       "   ShortDurationPrecipitationValue060  ShortDurationPrecipitationValue080  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "   ShortDurationPrecipitationValue100  ShortDurationPrecipitationValue120  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "   ShortDurationPrecipitationValue150  ShortDurationPrecipitationValue180  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "   Sunrise  Sunset  TStorms  WindEquipmentChangeDate  \n",
       "0      NaN     NaN      NaN               2007-06-27  \n",
       "1      NaN     NaN      NaN               2007-06-27  \n",
       "2      NaN     NaN      NaN               2007-06-27  \n",
       "3      NaN     NaN      NaN               2007-06-27  \n",
       "4      NaN     NaN      NaN               2007-06-27  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houston1 = pd.read_csv('./Houston_TX/Houston1948_1957.csv')\n",
    "houston2 = pd.read_csv('./Houston_TX/Houston1957_1966.csv')\n",
    "houston3 = pd.read_csv('./Houston_TX/Houston1966_1975.csv')\n",
    "houston4 = pd.read_csv('./Houston_TX/Houston1975_1984.csv')\n",
    "houston5 = pd.read_csv('./Houston_TX/Houston1984_1993.csv')\n",
    "houston6 = pd.read_csv('./Houston_TX/Houston1993_2002.csv')\n",
    "houston7 = pd.read_csv('./Houston_TX/Houston2002_2011.csv')\n",
    "houston8 = pd.read_csv('./Houston_TX/Houston2011_2020.csv')\n",
    "\n",
    "houston1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74550, 124)\n",
      "(73036, 124)\n",
      "(18824, 124)\n",
      "(85793, 124)\n",
      "(92828, 124)\n",
      "(144885, 124)\n",
      "(182064, 124)\n",
      "(99962, 124)\n"
     ]
    }
   ],
   "source": [
    "#verify the same number of columns\n",
    "print(houston1.shape)\n",
    "print(houston2.shape)\n",
    "print(houston3.shape)\n",
    "print(houston4.shape)\n",
    "print(houston5.shape)\n",
    "print(houston6.shape)\n",
    "print(houston7.shape)\n",
    "print(houston8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "#check column index\n",
    "print(houston1.columns == houston2.columns)\n",
    "print(houston2.columns == houston3.columns)\n",
    "print(houston3.columns == houston4.columns)\n",
    "print(houston4.columns == houston5.columns)\n",
    "print(houston5.columns == houston6.columns)\n",
    "print(houston6.columns == houston7.columns)\n",
    "print(houston7.columns == houston8.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate\n",
    "houston_list = [houston1, houston2, houston3, houston4, houston5, houston6, houston7, houston8]\n",
    "\n",
    "houston_all_data = pd.concat(houston_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check: there are 124 columns\n",
    "len(houston_all_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating, dropping columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe rows represent measurements taken at or determined over different periods of time, e.g. **Hourly** Data or **Daily** Data or **Monthly** Data. We'll group these in separate dataframes to reduce null counts and make more manageable.\n",
    "\n",
    "We'll also drop a few utterly useless columns, either blank or representing things we don't care about (e.g. latitude/longitude of the backup equipment).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TStorms: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### For example, Houston has had more than 0 Thunderstorms since the 1940s (source: I grew up in Houston, TX)\n",
    "#### Therefore, in my judgement this column should be removed\n",
    "\n",
    "column_list =['TStorms']\n",
    "             \n",
    "[print(f'{i}: {houston_all_data[i].value_counts().sum()}') for i in column_list]\n",
    "#houston_all_data['HourlyPresentWeatherType'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining dictionaries to drop\n",
    "The two dictionaries here are:\n",
    " - ##### drop_columns\n",
    "     - These should be removed entirely\n",
    " - ##### semi_drop\n",
    "     - Some of these should be removed, some should be kept depending on your use case\n",
    "     - They're grouped by time interval (hourly, daily, monthly) and alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2011-01-02T00:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2011-01-02T01:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2011-01-02T02:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2011-01-02T03:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2011-01-02T04:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99957</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2020-01-01T20:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99958</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2020-01-01T21:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99959</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2020-01-01T22:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99960</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2020-01-01T23:53:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99961</th>\n",
       "      <td>72244012918</td>\n",
       "      <td>2020-01-01T23:59:00</td>\n",
       "      <td>SOD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           STATION                 DATE REPORT_TYPE  SOURCE\n",
       "0      72244012918  2011-01-02T00:53:00       FM-15       7\n",
       "1      72244012918  2011-01-02T01:53:00       FM-15       7\n",
       "2      72244012918  2011-01-02T02:53:00       FM-15       7\n",
       "3      72244012918  2011-01-02T03:53:00       FM-15       7\n",
       "4      72244012918  2011-01-02T04:53:00       FM-15       7\n",
       "...            ...                  ...         ...     ...\n",
       "99957  72244012918  2020-01-01T20:53:00       FM-15       7\n",
       "99958  72244012918  2020-01-01T21:53:00       FM-15       7\n",
       "99959  72244012918  2020-01-01T22:53:00       FM-15       7\n",
       "99960  72244012918  2020-01-01T23:53:00       FM-15       7\n",
       "99961  72244012918  2020-01-01T23:59:00       SOD         6\n",
       "\n",
       "[99962 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = ['HeavyFog', 'REM', 'REPORT_TYPE.1', 'SOURCE.1',\n",
    "               \n",
    "                'BackupDirection',\"BackupDistance\",'BackupDistanceUnit','BackupElements','BackupElevation',\n",
    "                'BackupElevationUnit','BackupEquipment','BackupLatitude','BackupLongitude','BackupName',\n",
    "                \n",
    "                'MonthlyAverageRH', 'MonthlyDewpointTemperature', \n",
    "                \n",
    "                'TStorms',\n",
    "             \n",
    "                'WindEquipmentChangeDate'\n",
    "             ]\n",
    "\n",
    "semi_drop = ['AWND',\n",
    "                           \n",
    "             'CDSD','CLDD','DSNW',\n",
    "             \n",
    "             ###########################################################################################################\n",
    "             # daily data\n",
    "             'DailyAverageDewPointTemperature','DailyAverageDryBulbTemperature','DailyAverageRelativeHumidity',\n",
    "             'DailyAverageSeaLevelPressure','DailyAverageStationPressure', 'DailyAverageWetBulbTemperature',  \n",
    "             'DailyAverageWindSpeed', 'DailyCoolingDegreeDays', 'DailyDepartureFromNormalAverageTemperature', \n",
    "             'DailyHeatingDegreeDays', 'DailyMaximumDryBulbTemperature', 'DailyMinimumDryBulbTemperature', \n",
    "             'DailyPeakWindDirection', 'DailyPeakWindSpeed','DailyPrecipitation', 'DailySnowDepth', 'DailySnowfall', \n",
    "             'DailySustainedWindDirection', 'DailySustainedWindSpeed', 'DailyWeather',\n",
    "             \n",
    "             'HDSD','HTDD',\n",
    "             ##########################################################################################################\n",
    "             \n",
    "             ##########################################################################################################\n",
    "             # # hourly data\n",
    "             'HourlyAltimeterSetting', 'HourlyDewPointTemperature', 'HourlyDryBulbTemperature', 'HourlyPrecipitation', \n",
    "             'HourlyPresentWeatherType', 'HourlyPressureChange', 'HourlyPressureTendency', 'HourlyRelativeHumidity', \n",
    "             'HourlySeaLevelPressure', 'HourlySkyConditions', 'HourlyStationPressure','HourlyVisibility', \n",
    "             'HourlyWetBulbTemperature', 'HourlyWindDirection', 'HourlyWindGustSpeed','HourlyWindSpeed',\n",
    "             ##########################################################################################################\n",
    "             \n",
    "             ##########################################################################################################\n",
    "             # monthly data\n",
    "             'MonthlyDaysWithGT001Precip', 'MonthlyDaysWithGT010Precip', 'MonthlyDaysWithGT32Temp',\n",
    "             'MonthlyDaysWithGT90Temp', 'MonthlyDaysWithLT0Temp', 'MonthlyDaysWithLT32Temp',\n",
    "             'MonthlyDepartureFromNormalAverageTemperature', 'MonthlyDepartureFromNormalCoolingDegreeDays',\n",
    "             'MonthlyDepartureFromNormalHeatingDegreeDays', 'MonthlyDepartureFromNormalMaximumTemperature',\n",
    "             'MonthlyDepartureFromNormalMinimumTemperature', 'MonthlyDepartureFromNormalPrecipitation',\n",
    "             'MonthlyGreatestPrecip', 'MonthlyGreatestPrecipDate', 'MonthlyGreatestSnowDepth',\n",
    "             'MonthlyGreatestSnowDepthDate', 'MonthlyGreatestSnowfall', 'MonthlyGreatestSnowfallDate', 'MonthlyMaxSeaLevelPressureValue',\n",
    "             'MonthlyMaxSeaLevelPressureValueDate', 'MonthlyMaxSeaLevelPressureValueTime', 'MonthlyMaximumTemperature', \n",
    "             'MonthlyMeanTemperature', 'MonthlyMinSeaLevelPressureValue', 'MonthlyMinSeaLevelPressureValueDate', \n",
    "             'MonthlyMinSeaLevelPressureValueTime','MonthlyMinimumTemperature', 'MonthlySeaLevelPressure', \n",
    "             'MonthlyStationPressure', 'MonthlyTotalLiquidPrecipitation', 'MonthlyTotalSnowfall', 'MonthlyWetBulb',\n",
    "             ##########################################################################################################\n",
    "             \n",
    "             \n",
    "             'NormalsCoolingDegreeDay', 'NormalsHeatingDegreeDay',\n",
    "            \n",
    "             \n",
    "             ##########################################################################################################\n",
    "             # short duration(?) data\n",
    "             'ShortDurationEndDate005', 'ShortDurationEndDate010', 'ShortDurationEndDate015', 'ShortDurationEndDate020',\n",
    "             'ShortDurationEndDate030', 'ShortDurationEndDate045', 'ShortDurationEndDate060', 'ShortDurationEndDate080',\n",
    "             'ShortDurationEndDate100', 'ShortDurationEndDate120', 'ShortDurationEndDate150', 'ShortDurationEndDate180',\n",
    "             'ShortDurationPrecipitationValue005', 'ShortDurationPrecipitationValue010', 'ShortDurationPrecipitationValue015',\n",
    "             'ShortDurationPrecipitationValue020', 'ShortDurationPrecipitationValue030', 'ShortDurationPrecipitationValue045',\n",
    "             'ShortDurationPrecipitationValue060', 'ShortDurationPrecipitationValue080', 'ShortDurationPrecipitationValue100',\n",
    "             'ShortDurationPrecipitationValue120', 'ShortDurationPrecipitationValue150', 'ShortDurationPrecipitationValue180',\n",
    "             ##########################################################################################################\n",
    "             \n",
    "             'Sunrise','Sunset',\n",
    "             ] \n",
    "             ############ close dictionary ################\n",
    "\n",
    "drop_columns.extend(semi_drop)\n",
    "\n",
    "houston8.drop(columns = drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1948-07-01 00:00:00\n",
       "1        1948-07-01 01:00:00\n",
       "2        1948-07-01 02:00:00\n",
       "3        1948-07-01 03:00:00\n",
       "4        1948-07-01 04:00:00\n",
       "                 ...        \n",
       "771937   2020-01-01 20:53:00\n",
       "771938   2020-01-01 21:53:00\n",
       "771939   2020-01-01 22:53:00\n",
       "771940   2020-01-01 23:53:00\n",
       "771941   2020-01-01 23:59:00\n",
       "Name: DATE, Length: 771942, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houston_all_data['DATE'] = pd.to_datetime(houston_all_data['DATE'])\n",
    "houston_all_data['DATE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame lists of features\n",
    "These lists define the columns that will make up each DataFrame, grouped by time interval (daily, hourly, monthly, whatever \"short duration\" means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "             ###########################################################################################################\n",
    "             # daily data\n",
    "daily_list = ['DATE','DailyAverageDewPointTemperature','DailyAverageDryBulbTemperature','DailyAverageRelativeHumidity',\n",
    "             'DailyAverageSeaLevelPressure','DailyAverageStationPressure', 'DailyAverageWetBulbTemperature',  \n",
    "             'DailyAverageWindSpeed', 'DailyCoolingDegreeDays', 'DailyDepartureFromNormalAverageTemperature', \n",
    "             'DailyHeatingDegreeDays', 'DailyMaximumDryBulbTemperature', 'DailyMinimumDryBulbTemperature', \n",
    "             'DailyPeakWindDirection', 'DailyPeakWindSpeed','DailyPrecipitation', 'DailySnowDepth', 'DailySnowfall', \n",
    "             'DailySustainedWindDirection', 'DailySustainedWindSpeed', 'DailyWeather',\n",
    "             \n",
    "             'HDSD','HTDD',\n",
    "             ##########################################################################################################\n",
    "             ]\n",
    "\n",
    "             ##########################################################################################################\n",
    "             # # hourly data\n",
    "hourly_list = ['DATE','HourlyAltimeterSetting', 'HourlyDewPointTemperature', 'HourlyDryBulbTemperature', 'HourlyPrecipitation', \n",
    "             'HourlyPresentWeatherType', 'HourlyPressureChange', 'HourlyPressureTendency', 'HourlyRelativeHumidity', \n",
    "             'HourlySeaLevelPressure', 'HourlySkyConditions', 'HourlyStationPressure','HourlyVisibility', \n",
    "             'HourlyWetBulbTemperature', 'HourlyWindDirection', 'HourlyWindGustSpeed','HourlyWindSpeed',\n",
    "             ##########################################################################################################\n",
    "              ]\n",
    "\n",
    "             ##########################################################################################################\n",
    "             # monthly data\n",
    "monthly_list = ['DATE','MonthlyDaysWithGT001Precip', 'MonthlyDaysWithGT010Precip', 'MonthlyDaysWithGT32Temp',\n",
    "             'MonthlyDaysWithGT90Temp', 'MonthlyDaysWithLT0Temp', 'MonthlyDaysWithLT32Temp',\n",
    "             'MonthlyDepartureFromNormalAverageTemperature', 'MonthlyDepartureFromNormalCoolingDegreeDays',\n",
    "             'MonthlyDepartureFromNormalHeatingDegreeDays', 'MonthlyDepartureFromNormalMaximumTemperature',\n",
    "             'MonthlyDepartureFromNormalMinimumTemperature', 'MonthlyDepartureFromNormalPrecipitation',\n",
    "             'MonthlyGreatestPrecip', 'MonthlyGreatestPrecipDate', 'MonthlyGreatestSnowDepth',\n",
    "             'MonthlyGreatestSnowDepthDate', 'MonthlyGreatestSnowfall', 'MonthlyGreatestSnowfallDate', 'MonthlyMaxSeaLevelPressureValue',\n",
    "             'MonthlyMaxSeaLevelPressureValueDate', 'MonthlyMaxSeaLevelPressureValueTime', 'MonthlyMaximumTemperature', \n",
    "             'MonthlyMeanTemperature', 'MonthlyMinSeaLevelPressureValue', 'MonthlyMinSeaLevelPressureValueDate', \n",
    "             'MonthlyMinSeaLevelPressureValueTime','MonthlyMinimumTemperature', 'MonthlySeaLevelPressure', \n",
    "             'MonthlyStationPressure', 'MonthlyTotalLiquidPrecipitation', 'MonthlyTotalSnowfall', 'MonthlyWetBulb',\n",
    "             ##########################################################################################################\n",
    "             ]\n",
    "             \n",
    "             ##########################################################################################################\n",
    "             # short duration(?) data\n",
    "short_dur_list = ['DATE','ShortDurationEndDate005', 'ShortDurationEndDate010', 'ShortDurationEndDate015', 'ShortDurationEndDate020',\n",
    "             'ShortDurationEndDate030', 'ShortDurationEndDate045', 'ShortDurationEndDate060', 'ShortDurationEndDate080',\n",
    "             'ShortDurationEndDate100', 'ShortDurationEndDate120', 'ShortDurationEndDate150', 'ShortDurationEndDate180',\n",
    "             'ShortDurationPrecipitationValue005', 'ShortDurationPrecipitationValue010', 'ShortDurationPrecipitationValue015',\n",
    "             'ShortDurationPrecipitationValue020', 'ShortDurationPrecipitationValue030', 'ShortDurationPrecipitationValue045',\n",
    "             'ShortDurationPrecipitationValue060', 'ShortDurationPrecipitationValue080', 'ShortDurationPrecipitationValue100',\n",
    "             'ShortDurationPrecipitationValue120', 'ShortDurationPrecipitationValue150', 'ShortDurationPrecipitationValue180',\n",
    "             ##########################################################################################################\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "houston_daily = houston_all_data[daily_list].copy()\n",
    "houston_hourly = houston_all_data[hourly_list].copy()\n",
    "houston_monthly = houston_all_data[monthly_list].copy()\n",
    "houston_short_dur = houston_all_data[short_dur_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73      24937\n",
       "72      21576\n",
       "75      20473\n",
       "70      19674\n",
       "73.0    15832\n",
       "        ...  \n",
       "88          1\n",
       "-3          1\n",
       "83          1\n",
       "57s         1\n",
       "0           1\n",
       "Name: HourlyDewPointTemperature, Length: 241, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houston_hourly['HourlyDewPointTemperature'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "Right now most of the columns need a bit more scrubbing, accounting for nulls, datatype conversion, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 771942 entries, 0 to 771941\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   DATE                       771942 non-null  datetime64[ns]\n",
      " 1   HourlyAltimeterSetting     534142 non-null  object        \n",
      " 2   HourlyDewPointTemperature  655483 non-null  object        \n",
      " 3   HourlyDryBulbTemperature   655912 non-null  object        \n",
      " 4   HourlyPrecipitation        224787 non-null  object        \n",
      " 5   HourlyPresentWeatherType   137795 non-null  object        \n",
      " 6   HourlyPressureChange       114684 non-null  object        \n",
      " 7   HourlyPressureTendency     115463 non-null  float64       \n",
      " 8   HourlyRelativeHumidity     655473 non-null  object        \n",
      " 9   HourlySeaLevelPressure     494506 non-null  object        \n",
      " 10  HourlySkyConditions        277609 non-null  object        \n",
      " 11  HourlyStationPressure      307769 non-null  object        \n",
      " 12  HourlyVisibility           685780 non-null  object        \n",
      " 13  HourlyWetBulbTemperature   307672 non-null  object        \n",
      " 14  HourlyWindDirection        679428 non-null  object        \n",
      " 15  HourlyWindGustSpeed        45237 non-null   object        \n",
      " 16  HourlyWindSpeed            686058 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(15)\n",
      "memory usage: 100.1+ MB\n"
     ]
    }
   ],
   "source": [
    "houston_hourly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "houston_daily.to_csv('./Houston_TX/houston_daily.csv')\n",
    "houston_hourly.to_csv('./Houston_TX/houston_hourly.csv')\n",
    "houston_monthly.to_csv('./Houston_TX/houston_monthly.csv')\n",
    "houston_short_dur.to_csv('./Houston_TX/houston_short_dur.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
